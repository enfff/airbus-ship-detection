{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9988,"databundleVersionId":868324,"sourceType":"competition"},{"sourceId":8438193,"sourceType":"datasetVersion","datasetId":5026303},{"sourceId":8516397,"sourceType":"datasetVersion","datasetId":5084559}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n# MAIN CONFIGURATIONS\ncreate_log_file = True\nsave_to_drive = False\nmodel_id = '3'  # We will train multiple models with the same settings. Keep it as a string!\nnum_epochs = 20\nbatch_size = 32\ndata_augmentation_type = 'noaug'  # Which data augmentation tecnique are we using?\n                                  # 'noaug':     no data augmentation\n\n# !tree # Prints folder structure\n\ntest_only = False # when true it doesn't train the model, but it just tests an existing one\ntrain_again = False # Trains the model again for num_epoch times\n\nmodel_filepath = f\"model_epochs{str(num_epochs)}_{data_augmentation_type}_id{model_id}\"\nmodel_filepath = os.path.join(\"models\", model_filepath)\nprint(f\"{model_filepath = }\")\n\nos.makedirs(model_filepath, exist_ok=True)","metadata":{"_uuid":"f66e8f23-9459-4a78-b42d-592a8b72fd93","_cell_guid":"1eb3601c-59c5-4c49-8c24-91184a27a7e1","collapsed":false,"id":"NFc7Y_31k39Q","outputId":"13bf00d1-bde8-49aa-b24b-2e49f08ab1ab","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:23:59.306506Z","iopub.execute_input":"2024-05-26T09:23:59.307036Z","iopub.status.idle":"2024-05-26T09:23:59.317736Z","shell.execute_reply.started":"2024-05-26T09:23:59.306997Z","shell.execute_reply":"2024-05-26T09:23:59.316352Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"model_filepath = 'models/model_epochs20_noaug_id3'\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.models as models\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport glob\nimport pandas as pd\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import rotate\nimport numpy as np\n\n# !pip install torchsummary\n# from torchsummary import summary\n!pip install torchmetrics\n!pip install pycocotools faster-coco-eval\n!pip install torchmetrics[detection]","metadata":{"_uuid":"3a8323c1-3053-4c12-9ade-4fb84ebf9533","_cell_guid":"f18fd6df-1d38-488c-8322-fe053a7d6424","collapsed":false,"id":"kA71_KIbk72N","outputId":"4c825fdc-4725-4bc9-9f3f-c7f07e6431dd","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:24:19.180622Z","iopub.execute_input":"2024-05-26T09:24:19.181121Z","iopub.status.idle":"2024-05-26T09:25:16.834316Z","shell.execute_reply.started":"2024-05-26T09:24:19.181084Z","shell.execute_reply":"2024-05-26T09:25:16.832978Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.1.2+cpu)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nCollecting pycocotools\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting faster-coco-eval\n  Downloading faster_coco_eval-1.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from faster-coco-eval) (5.18.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from faster-coco-eval) (2.2.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from faster-coco-eval) (9.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->faster-coco-eval) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->faster-coco-eval) (2023.4)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->faster-coco-eval) (8.2.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading faster_coco_eval-1.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (596 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools, faster-coco-eval\nSuccessfully installed faster-coco-eval-1.5.4 pycocotools-2.0.7\nRequirement already satisfied: torchmetrics[detection] in /opt/conda/lib/python3.10/site-packages (1.3.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (2.1.2+cpu)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (0.11.2)\nRequirement already satisfied: pycocotools>2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (2.0.7)\nRequirement already satisfied: torchvision>=0.8 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (0.16.2+cpu)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics[detection]) (69.0.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics[detection]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics[detection]) (3.1.1)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools>2.0.0->torchmetrics[detection]) (3.7.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8->torchmetrics[detection]) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8->torchmetrics[detection]) (9.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics[detection]) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics[detection]) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import logging\nfrom datetime import datetime\n\nif create_log_file:\n    logger = logging.getLogger('RootLogger')\n    log_filepath = datetime.now().strftime(\"%m-%d_%H.%M.%S\")\n    log_filepath = os.path.join(model_filepath, f\"log_{log_filepath}\" + \".txt\")\n    print(f\"{log_filepath = }\")\n    \n    logging.basicConfig(filename=log_filepath,\n                        filemode='a',\n                        format='%(asctime)s %(levelname)s %(message)s',\n                        level=logging.DEBUG,\n                        datefmt='%m-%d %H:%M:%S',\n                        force=True)\nelse:\n    logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n                        level=logging.DEBUG,\n                        datefmt='%m-%d %H:%M:%S',\n                        force=True)","metadata":{"_uuid":"e83dab63-8809-4b35-b264-4f1469682d4e","_cell_guid":"cefe5666-0a12-42de-90e4-9e6bfeeab010","collapsed":false,"id":"03slXsApk-6S","outputId":"30d3206d-bb54-495f-9e71-22ea77ee8cd0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:25:22.361172Z","iopub.execute_input":"2024-05-26T09:25:22.362882Z","iopub.status.idle":"2024-05-26T09:25:22.375785Z","shell.execute_reply.started":"2024-05-26T09:25:22.362795Z","shell.execute_reply":"2024-05-26T09:25:22.374442Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"log_filepath = 'models/model_epochs20_noaug_id3/log_05-26_09.25.22.txt'\n","output_type":"stream"}]},{"cell_type":"code","source":"# TRANSFORMATIONS\n\nfrom torchvision.transforms import v2\n\nimg_dimensions = 224\n\n# Normalize to the ImageNet mean and standard deviation\n# Could calculate it for the cats/dogs data set, but the ImageNet\n# values give acceptable results here.\nimg_train_transforms = v2.Compose([\n     v2.RandomRotation(50),\n     v2.RandomAffine(degrees = 0, translate = (0.2, 0.2)),\n     v2.RandomHorizontalFlip(p=0.5),\n    v2.Resize((img_dimensions, img_dimensions)),\n     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n     v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\n\nimg_validation_transforms = v2.Compose([\n    v2.Resize((img_dimensions, img_dimensions)),\n     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n     v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])","metadata":{"_uuid":"86622d71-08ab-4f4a-8f6b-d8d20a66ee67","_cell_guid":"02a5ff4a-6f79-47fc-8863-6c66282ac3cf","collapsed":false,"id":"LIgECtVqMlCI","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T11:23:13.772104Z","iopub.execute_input":"2024-05-26T11:23:13.772740Z","iopub.status.idle":"2024-05-26T11:23:13.787979Z","shell.execute_reply.started":"2024-05-26T11:23:13.772686Z","shell.execute_reply":"2024-05-26T11:23:13.786566Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport torchvision.transforms.functional as F\n\ndef rl_decode(rl_str, height, length):\n  mask = np.zeros(shape=(1,height,length))\n  couples = rl_str.split()\n  for i in range(0, len(couples)-1, 2):\n    # print(i)\n    el = int(couples[i])\n    qty = int(couples[i+1])\n    r,c = np.unravel_index(el,(height,length))\n    for j in range(qty):\n      # mask[0, r, c+j] = 1\n      mask[0, c+j-1, r-1] = 1\n\n    # print(torch.Tensor(mask))\n  return torch.Tensor(mask).reshape((768, 768)).gt(0)\n\ndef show(imgs, rotation=None):\n\n    if rotation:\n          imgs = rotate(imgs, rotation)\n\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n    for i, img in enumerate(imgs):\n        img = img.detach()\n        img = F.to_pil_image(img)\n        axs[0, i].imshow(np.asarray(img))\n        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n\nclass ShipsDataset(torch.utils.data.Dataset):\n    def __init__(self, file_list, targets, transforms = None, target_transforms = None):\n        self.file_list = file_list\n        self.targets = targets\n        self.transform = transforms\n\n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n\n    def __getitem__(self, idx):\n        image = read_image(self.file_list[idx])    # numpy tensor\n\n        image = F.convert_image_dtype(image)\n        # Added this line to fix this problem (ENF) during training\n        # TypeError: Expected input images to be of floating type (in range [0, 1]), but found type torch.uint8 instead\n\n        # try:\n        label = self.targets[idx]       # dictionary {\"boxes\": , \"label\": }\n        label['boxes'] = torch.Tensor(label['boxes'])\n        label['labels'] = torch.Tensor(label['labels']).to(dtype=torch.int64).reshape((-1,))\n        # except IndexError as e:\n        #     Warning(f'Errore con {idx = }')\n        #     plt.imshow(image.permute(1, 2, 0))\n        #     plt.show()\n\n        if self.transform:\n            image = self.transform(image, label)\n\n            # prova ad indagare da qui\n            # image = self.transform(image)\n            # image = image.numpy()\n            # return image, label\n            # print(f\"{image = }\")\n            # print(f\"{label = }\")\n\n        return image, label","metadata":{"_uuid":"9d46e794-e37a-4cc3-afc4-4c31a63768a3","_cell_guid":"d7c3fba5-7966-4876-a902-31971e6e4121","collapsed":false,"id":"V1Q6ogjksMqE","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:25:43.622452Z","iopub.execute_input":"2024-05-26T09:25:43.623350Z","iopub.status.idle":"2024-05-26T09:25:43.641062Z","shell.execute_reply.started":"2024-05-26T09:25:43.623287Z","shell.execute_reply":"2024-05-26T09:25:43.639774Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\nfrom torchvision import tv_tensors\n\n# DATASET_DIR = os.path.join(\".\")\nTRAIN_DIR = \"/kaggle/input/airbus-ship-detection/train_v2\"\nTEST_DIR = \"/kaggle/input/airbus-ship-detection/test_v2\"\n# print(DATASET_DIR, TRAIN_DIR, TEST_DIR)\n\ntrain_list = glob.glob(os.path.join(TRAIN_DIR,'*.jpg'))\ntrain_list, test_list = train_test_split(train_list, test_size = 0.99)\ntrain_list, val_list = train_test_split(train_list, test_size = 0.2)\ntest_list, _ = train_test_split(test_list, test_size = 0.99)\ntest_list, _ = train_test_split(test_list, test_size = 0.5)\n\ntrain_data = ShipsDataset(train_list, transforms = img_train_transforms, targets=np.load('/kaggle/input/rcnn-dataset-py/rcnn_targets.npy', allow_pickle='TRUE'))\ntest_data = ShipsDataset(test_list, transforms = img_train_transforms, targets=np.load('/kaggle/input/rcnn-dataset-py/rcnn_targets.npy', allow_pickle='TRUE'))\nval_data = ShipsDataset(val_list, transforms = img_train_transforms,targets=np.load('/kaggle/input/rcnn-dataset-py/rcnn_targets.npy', allow_pickle='TRUE') )\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True, collate_fn=lambda x: x)\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle = True, collate_fn=lambda x: x)\ntest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True, collate_fn=lambda x: x)\n\n\"\"\"\nimport pickle\n\n# Salva i DataLoader\nwith open(os.path.join(model_filepath, 'train_loader.pkl'), 'wb') as f:\n    pickle.dump(train_loader, f)\n\nwith open(os.path.join(model_filepath, 'val_loader.pkl'), 'wb') as f:\n    pickle.dump(val_loader, f)\n\nwith open(os.path.join(model_filepath, 'test_loader.pkl'), 'wb') as f:\n    pickle.dump(test_loader, f)\n\n\"\"\"\n\n# print(len(train_data),len(train_loader))\n# print(len(val_data), len(val_loader))\nprint(len(test_loader))\n\n# https://pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html#torchvision.models.detection.fasterrcnn_resnet50_fpn\n# La documentazione non è chiara sulla posizione dei punti per le ground-truth!\n# /Users/ludovicamazzucco/Library/Python/3.9/lib/python/site-packages/torchvision/models/detection/generalized_rcnn.py\"","metadata":{"_uuid":"e881bc76-8dce-441c-8229-3a46d9083e40","_cell_guid":"734a631c-9fb5-451d-844c-a7ab77f6b9ff","collapsed":false,"id":"YW9039lzlK5S","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T11:25:30.775165Z","iopub.execute_input":"2024-05-26T11:25:30.775946Z","iopub.status.idle":"2024-05-26T11:28:13.294717Z","shell.execute_reply.started":"2024-05-26T11:25:30.775903Z","shell.execute_reply":"2024-05-26T11:28:13.293085Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"30\n","output_type":"stream"}]},{"cell_type":"code","source":"## STEP 1. freeze backbone layers, add final layers and train the network\n\nmodel_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n\nfor name, param in model_rcnn.named_parameters():\n      param.requires_grad = False\n\nnum_classes = 2 # background, ship\nin_features = model_rcnn.roi_heads.box_predictor.cls_score.in_features\nmodel_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","metadata":{"_uuid":"d03e9038-bb70-4a25-844c-caf367db09b3","_cell_guid":"205f69cf-8dd0-443e-a21a-345bb8c0a3ac","collapsed":false,"id":"5J9M_bnAxnDk","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T11:29:54.725985Z","iopub.execute_input":"2024-05-26T11:29:54.726527Z","iopub.status.idle":"2024-05-26T11:29:54.737117Z","shell.execute_reply.started":"2024-05-26T11:29:54.726487Z","shell.execute_reply":"2024-05-26T11:29:54.735668Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\n# How to save in google drive something else\n# if save_to_drive:\n#   with open('/content/drive/MyDrive/MLVM_project/file.txt', 'w') as f:\n#     f.write('content')\n\nprint(f\"{model_filepath = }\")\n\ndef save_checkpoint(epoch, model, optimizer, train_loss, val_loss=0, model_name=\"model.tar\"):\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'train_loss': train_loss,\n        'val_loss': val_loss\n    }, os.path.join(model_filepath, model_name))\n    print(\"Saved model\")","metadata":{"_uuid":"6eba70ff-96e9-4522-b787-d1946d2b9017","_cell_guid":"528b2af3-593a-4e0a-ae5b-ef64c8d760e4","collapsed":false,"id":"Du5q6_RRCmD4","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:28:54.632458Z","iopub.execute_input":"2024-05-26T09:28:54.632936Z","iopub.status.idle":"2024-05-26T09:28:54.641265Z","shell.execute_reply.started":"2024-05-26T09:28:54.632900Z","shell.execute_reply":"2024-05-26T09:28:54.640369Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"model_filepath = 'models/model_epochs20_noaug_id3'\n","output_type":"stream"}]},{"cell_type":"code","source":"# TRAIN\nimport gc\n\ndef train(model, optimizer, loss_fn, train_loader, val_loader, epochs=1, device=\"cpu\"):\n \n    for epoch in range(epochs):\n        training_loss = 0.0\n        batch_cumsum = 0\n        model.train()\n\n        for i, batch in enumerate(train_loader):\n            logger.info(f\"E: {str(epoch)} B: {str(i)}\")\n            print(f\"epoch {epoch} batch {i}\")\n            batch_cumsum += len(batch) # needed to compute the training loss later\n            optimizer.zero_grad()\n\n            # filtering out empty images (model does not accept empty targets)\n            inputs = []\n            targets = []\n            for el in batch:       # el = (image,labels)\n                if el[1]['boxes'].size()[0] != 0:\n                    inputs.append(el[0][0])\n                    targets.append(el[0][1])\n                    # print(f\"{el = }\")\n                    # Example el\n                    # el = (tensor([[[0.1006, 0.1249, 0.1552,  ..., 0.1552, 0.1395, 0.1321],\n                    #          [0.1224, 0.1331, 0.1243,  ..., 0.1218, 0.1260, 0.1410],\n                    #          [0.0948, 0.1149, 0.1300,  ..., 0.1381, 0.1356, 0.1356],\n                    #          ...,\n                    #          [0.1789, 0.1738, 0.1818,  ..., 0.1401, 0.1428, 0.1169],\n                    #          [0.1591, 0.1532, 0.1752,  ..., 0.1555, 0.1481, 0.1131],\n                    #          [0.1664, 0.1698, 0.1564,  ..., 0.1268, 0.1538, 0.1393]],\n\n                    #         [[0.2291, 0.2504, 0.2689,  ..., 0.2807, 0.2650, 0.2576],\n                    #          [0.2510, 0.2586, 0.2380,  ..., 0.2473, 0.2515, 0.2664],\n                    #          [0.2234, 0.2404, 0.2437,  ..., 0.2636, 0.2611, 0.2611],\n                    #          ...,\n                    #          [0.2966, 0.2914, 0.2995,  ..., 0.2460, 0.2486, 0.2228],\n                    #          [0.2768, 0.2709, 0.2928,  ..., 0.2613, 0.2540, 0.2190],\n                    #          [0.2840, 0.2874, 0.2741,  ..., 0.2327, 0.2596, 0.2452]],\n\n                    #         [[0.2880, 0.3092, 0.3317,  ..., 0.3396, 0.3238, 0.3164],\n                    #          [0.3098, 0.3174, 0.3007,  ..., 0.3062, 0.3103, 0.3253],\n                    #          [0.2822, 0.2993, 0.3064,  ..., 0.3224, 0.3199, 0.3199],\n                    #          ...,\n                    #          [0.3358, 0.3306, 0.3387,  ..., 0.2813, 0.2918, 0.2659],\n                    #          [0.3160, 0.3101, 0.3320,  ..., 0.2966, 0.2971, 0.2622],\n                    #          [0.3232, 0.3266, 0.3133,  ..., 0.2680, 0.3028, 0.2883]]]), {'boxes': tensor([[0.3932, 0.8464, 0.5208, 0.8776],\n                    #         [0.2331, 0.2643, 0.3268, 0.3060],\n                    #         [0.2435, 0.2995, 0.4062, 0.3724],\n                    #         [0.7188, 0.6198, 0.8281, 0.6784],\n                    #         [0.2279, 0.3229, 0.4154, 0.4128]]), 'labels': tensor([1, 1, 1, 1, 1])})\n                    \n            if len(inputs) == 0:\n                continue\n            \n           # inputs = inputs.to(device)\n           # targets = targets.to(device)\n            output = model(inputs,targets)  # NOTE: output is a dict with already computed losses within!\n\n            \"\"\" EXAMPLE :\n            {'loss_classifier': tensor(1.0206, grad_fn=<NllLossBackward0>),\n             'loss_box_reg': tensor(0.0071, grad_fn=<DivBackward0>),\n             'loss_objectness': tensor(1.8541), 'loss_rpn_box_reg': tensor(1.8591)}\n             \n             How losses are computed:\n             \n             -loss_classifier-\n             classification_loss = F.cross_entropy(class_logits, labels)\n             \n             -loss_box_reg-\n             box_loss = F.smooth_l1_loss(\n                box_regression[sampled_pos_inds_subset, labels_pos],\n                regression_targets[sampled_pos_inds_subset],\n                beta=1 / 9,\n                reduction=\"sum\",\n            )\n            box_loss = box_loss / labels.numel()\n            \n            -loss_rpn_box_reg-\n            box_loss = F.smooth_l1_loss(\n            pred_bbox_deltas[sampled_pos_inds],\n            regression_targets[sampled_pos_inds],\n            beta=1 / 9,\n            reduction=\"sum\",\n            ) / (sampled_inds.numel())\n            \n            -loss_objectness-\n            objectness_loss = F.binary_cross_entropy_with_logits(objectness[sampled_inds], labels[sampled_inds])\n             \n             \"\"\"\n          \n            loss = sum(loss for loss in output.values())\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.data.item() *len(batch)\n            \n            del inputs\n            del targets\n            gc.collect()    \n        \n        training_loss /= batch_cumsum\n        save_checkpoint(epoch, model, optimizer, training_loss)\n        \n        # VALIDATION\n           \n        model.train()\n        num_correct = 0\n        num_examples = 0\n        valid_loss = 0\n        \n        with torch.no_grad():\n            for i,batch in enumerate(val_loader):\n                print(\"batch\", i)\n                inputs = []\n                targets = []\n\n                for el in batch:       # el = (image,labels)\n                    if el[1]['boxes'].size()[0] != 0:\n                        inputs.append(el[0][0])\n                        targets.append(el[0][1])\n\n                if len(inputs) == 0:\n                    continue\n                # inputs = inputs.to(device)\n                output = model(inputs, targets)\n\n                # print(f\"{output = }\")\n                # targets = targets.to(device)\n                loss = sum(loss for loss in output.values())\n                valid_loss += loss.data.item() *len(batch)\n\n                del inputs\n                del targets\n                gc.collect()\n\n        valid_loss /= len(val_loader.dataset)\n        \n        print( 'Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, training_loss,\n        valid_loss))\n\n        logger.info('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, training_loss,\n        valid_loss))\n        \n\n# from torchvision.utils import draw_bounding_boxes\n# score_threshold = .5","metadata":{"_uuid":"a9a507f8-c784-4847-a373-79f1a84ba9aa","_cell_guid":"ee5ce9ae-8a53-4e0e-9db9-99e5a583fd43","collapsed":false,"id":"Mv8b06EulUK2","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:29:02.057697Z","iopub.execute_input":"2024-05-26T09:29:02.058622Z","iopub.status.idle":"2024-05-26T09:29:02.081716Z","shell.execute_reply.started":"2024-05-26T09:29:02.058570Z","shell.execute_reply":"2024-05-26T09:29:02.079820Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")","metadata":{"_uuid":"320e60fe-fabe-487b-91d3-a2b3d5965cba","_cell_guid":"3d46d08a-3a51-4452-b79e-882309e42a16","collapsed":false,"id":"LloRuEg8lWyf","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T09:29:08.076321Z","iopub.execute_input":"2024-05-26T09:29:08.076833Z","iopub.status.idle":"2024-05-26T09:29:08.082909Z","shell.execute_reply.started":"2024-05-26T09:29:08.076796Z","shell.execute_reply":"2024-05-26T09:29:08.081643Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = model_rcnn.to(device)\ntorch.compile(model)\noptimizer = optim.Adam(params = model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()","metadata":{"_uuid":"5a384475-40a4-4c13-9c8a-8efeb96ed8f2","_cell_guid":"2f312861-b958-45c9-92e5-ed33d593194f","collapsed":false,"id":"2LUibV2Elccf","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-26T11:30:12.645947Z","iopub.execute_input":"2024-05-26T11:30:12.646440Z","iopub.status.idle":"2024-05-26T11:30:12.682070Z","shell.execute_reply.started":"2024-05-26T11:30:12.646405Z","shell.execute_reply":"2024-05-26T11:30:12.680437Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# START MODEL TRAINING\nif not test_only:\n    train(model, optimizer, torch.nn.CrossEntropyLoss(), train_loader, val_loader, epochs=num_epochs, device=device)\n    torch.save(model.state_dict(), 'model_state_dict')","metadata":{"_uuid":"a79ed4b4-e470-4dfc-8f51-ef43b63f3ae5","_cell_guid":"620eeb9f-ac5f-4f99-b241-c62df61659a8","id":"COB3KM9Fx4i7","execution":{"iopub.status.busy":"2024-05-26T11:30:31.613637Z","iopub.execute_input":"2024-05-26T11:30:31.614140Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch 0 batch 0\nepoch 0 batch 1\nepoch 0 batch 2\nepoch 0 batch 3\nepoch 0 batch 4\nepoch 0 batch 5\nepoch 0 batch 6\nepoch 0 batch 7\nepoch 0 batch 8\nepoch 0 batch 9\nepoch 0 batch 10\nepoch 0 batch 11\nepoch 0 batch 12\nepoch 0 batch 13\nepoch 0 batch 14\nepoch 0 batch 15\nepoch 0 batch 16\nepoch 0 batch 17\nepoch 0 batch 18\nepoch 0 batch 19\nepoch 0 batch 20\nepoch 0 batch 21\nepoch 0 batch 22\nepoch 0 batch 23\nepoch 0 batch 24\nepoch 0 batch 25\nepoch 0 batch 26\nepoch 0 batch 27\nepoch 0 batch 28\nepoch 0 batch 29\nepoch 0 batch 30\nepoch 0 batch 31\nepoch 0 batch 32\nepoch 0 batch 33\nepoch 0 batch 34\nepoch 0 batch 35\nepoch 0 batch 36\nepoch 0 batch 37\nepoch 0 batch 38\nepoch 0 batch 39\nepoch 0 batch 40\nepoch 0 batch 41\nepoch 0 batch 42\nepoch 0 batch 43\nepoch 0 batch 44\nepoch 0 batch 45\nepoch 0 batch 46\nepoch 0 batch 47\nepoch 0 batch 48\nSaved model\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 5\nbatch 6\nbatch 7\nbatch 8\nbatch 9\nbatch 10\nbatch 11\nbatch 12\nEpoch: 0, Training Loss: 4.1514, Validation Loss: 3.9723\nepoch 1 batch 0\nepoch 1 batch 1\nepoch 1 batch 2\nepoch 1 batch 3\nepoch 1 batch 4\nepoch 1 batch 5\nepoch 1 batch 6\nepoch 1 batch 7\nepoch 1 batch 8\nepoch 1 batch 9\nepoch 1 batch 10\nepoch 1 batch 11\nepoch 1 batch 12\nepoch 1 batch 13\nepoch 1 batch 14\nepoch 1 batch 15\nepoch 1 batch 16\nepoch 1 batch 17\nepoch 1 batch 18\nepoch 1 batch 19\nepoch 1 batch 20\nepoch 1 batch 21\nepoch 1 batch 22\nepoch 1 batch 23\nepoch 1 batch 24\nepoch 1 batch 25\nepoch 1 batch 26\nepoch 1 batch 27\nepoch 1 batch 28\nepoch 1 batch 29\nepoch 1 batch 30\nepoch 1 batch 31\nepoch 1 batch 32\nepoch 1 batch 33\nepoch 1 batch 34\nepoch 1 batch 35\nepoch 1 batch 36\nepoch 1 batch 37\nepoch 1 batch 38\nepoch 1 batch 39\nepoch 1 batch 40\nepoch 1 batch 41\nepoch 1 batch 42\nepoch 1 batch 43\nepoch 1 batch 44\nepoch 1 batch 45\nepoch 1 batch 46\nepoch 1 batch 47\nepoch 1 batch 48\nSaved model\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 5\nbatch 6\nbatch 7\nbatch 8\nbatch 9\nbatch 10\nbatch 11\nbatch 12\nEpoch: 1, Training Loss: 3.9314, Validation Loss: 3.8057\nepoch 2 batch 0\nepoch 2 batch 1\nepoch 2 batch 2\nepoch 2 batch 3\nepoch 2 batch 4\nepoch 2 batch 5\nepoch 2 batch 6\nepoch 2 batch 7\nepoch 2 batch 8\nepoch 2 batch 9\nepoch 2 batch 10\nepoch 2 batch 11\nepoch 2 batch 12\nepoch 2 batch 13\nepoch 2 batch 14\nepoch 2 batch 15\nepoch 2 batch 16\nepoch 2 batch 17\nepoch 2 batch 18\nepoch 2 batch 19\nepoch 2 batch 20\nepoch 2 batch 21\nepoch 2 batch 22\nepoch 2 batch 23\nepoch 2 batch 24\nepoch 2 batch 25\nepoch 2 batch 26\nepoch 2 batch 27\nepoch 2 batch 28\nepoch 2 batch 29\nepoch 2 batch 30\nepoch 2 batch 31\nepoch 2 batch 32\nepoch 2 batch 33\nepoch 2 batch 34\nepoch 2 batch 35\nepoch 2 batch 36\nepoch 2 batch 37\nepoch 2 batch 38\nepoch 2 batch 39\nepoch 2 batch 40\nepoch 2 batch 41\nepoch 2 batch 42\nepoch 2 batch 43\nepoch 2 batch 44\nepoch 2 batch 45\nepoch 2 batch 46\nepoch 2 batch 47\nepoch 2 batch 48\nSaved model\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 5\nbatch 6\nbatch 7\nbatch 8\nbatch 9\nbatch 10\nbatch 11\nbatch 12\nEpoch: 2, Training Loss: 3.8901, Validation Loss: 3.9151\nepoch 3 batch 0\nepoch 3 batch 1\nepoch 3 batch 2\nepoch 3 batch 3\nepoch 3 batch 4\nepoch 3 batch 5\nepoch 3 batch 6\nepoch 3 batch 7\nepoch 3 batch 8\nepoch 3 batch 9\nepoch 3 batch 10\nepoch 3 batch 11\nepoch 3 batch 12\nepoch 3 batch 13\nepoch 3 batch 14\nepoch 3 batch 15\n","output_type":"stream"}]},{"cell_type":"code","source":"# Per scaricare il contenuto di kaggle/working (e quindi recuperare i modelli)\n# Crea lo zip della cartella che è stata creata contenente il modello e i log\n\nif not test_only:\n    from IPython.display import FileLink\n    !zip -r file.zip {model_filepath}\n    FileLink(r'file.zip')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:17:13.986102Z","iopub.execute_input":"2024-05-21T18:17:13.986615Z","iopub.status.idle":"2024-05-21T18:17:13.999279Z","shell.execute_reply.started":"2024-05-21T18:17:13.986575Z","shell.execute_reply":"2024-05-21T18:17:13.998108Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"\nfrom torchmetrics.detection import MeanAveragePrecision\n\ndef test(model, test_loader, device=\"cpu\"):   \n    model.eval()\n    num_correct = 0\n    num_examples = 0\n    test_loss = 0\n    metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds=[0.75])\n    mAP = 0\n    \n    for i,batch in enumerate(test_loader):\n        print(\"batch\", i)\n        \n        inputs = []\n        targets = []\n        \n        for el in batch:       # el = (image,labels)\n            if el[1]['boxes'].size()[0] != 0:\n                inputs.append(el[0][0])\n                targets.append(el[0][1])\n        \n        if len(inputs) == 0:\n            continue\n        \n        # inputs = inputs.to(device)\n        output = model(inputs)\n        print(\"out :\\n\", output)\n        print(\"target :\\n\",targets)\n                \n        #     # Example output\n        #     {'boxes': tensor([[ 0.3801,  0.3060,  3.5638,  3.0348],\n        #     [ 0.2037,  0.6570,  1.9538,  4.9389],\n        #     [ 0.4993,  0.7045,  5.1531,  5.5368],\n        #     [ 0.7172,  0.0860,  8.0819,  3.2724],\n        #     [ 0.3548,  1.4842,  3.9183,  9.8673],\n        #     [ 0.9226,  0.4096, 11.7943,  6.0310]], grad_fn=<StackBackward0>),\n        #     labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.9762, 0.9498, 0.9188, 0.8941, 0.3722, 0.2909],\n        #     grad_fn=<IndexBackward0>)},\n        \n        \"\"\"\n        scores come from RoIHeads class:\n        pred_scores = F.softmax(class_logits, -1)\n        after deleting empy boxes, low scored boxes and applying non-max suppression\n        \"\"\"\n        res = metric(output,targets)\n        mAP += res['map_75']\n        #print(res)\n        \n        del inputs\n        del targets\n        gc.collect()\n        \n    mAP /= len(test_loader)  \n    print( 'Mean Average Precision: {:.4f}'.format(mAP))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:04:59.989863Z","iopub.execute_input":"2024-05-26T11:04:59.990396Z","iopub.status.idle":"2024-05-26T11:05:00.005897Z","shell.execute_reply.started":"2024-05-26T11:04:59.990348Z","shell.execute_reply":"2024-05-26T11:05:00.004399Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# START MODEL TEST\n\ncheckpoint = torch.load(os.path.join('/kaggle/input/model-trained', \"model.tar\"))\nmodel.load_state_dict(checkpoint['model_state_dict'])\ntest(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T11:05:06.107895Z","iopub.execute_input":"2024-05-26T11:05:06.109396Z","iopub.status.idle":"2024-05-26T11:16:24.655745Z","shell.execute_reply.started":"2024-05-26T11:05:06.109308Z","shell.execute_reply":"2024-05-26T11:16:24.653488Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"batch 0\nout :\n [{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.4170, 1.9893],\n        [0.0000, 0.0360, 2.1648, 1.3752],\n        [0.0000, 0.0000, 0.4701, 1.7146],\n        [0.0000, 0.0000, 0.8210, 0.9308],\n        [0.0000, 0.0413, 2.9555, 2.1496],\n        [1.1489, 0.1017, 4.6799, 1.3308]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2727, 0.1856, 0.1286, 0.1240, 0.1055, 0.0974],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[3.6897e-03, 4.2645e-03, 1.4021e+00, 2.1397e+00],\n        [1.6738e-02, 0.0000e+00, 1.1646e+00, 1.1312e+00],\n        [5.1954e-03, 3.1326e+00, 6.4470e-01, 9.1672e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.4493, 0.3027, 0.0516], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.6041e-02, 1.1310e+00, 2.4889e+00],\n        [0.0000e+00, 2.0855e-04, 5.3668e-01, 2.3180e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.5388, 0.4154], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.2266, 2.0862],\n        [0.0000, 0.0137, 1.2649, 2.3950]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2651, 0.2343], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 2.6562e-03, 1.1952e+00, 1.8111e+00],\n        [0.0000e+00, 6.8984e-02, 2.2577e+00, 1.1795e+00],\n        [0.0000e+00, 2.1972e-03, 8.0711e-01, 8.6258e-01],\n        [0.0000e+00, 0.0000e+00, 4.9926e-01, 1.8723e+00],\n        [9.6289e-01, 1.3794e-01, 4.7465e+00, 1.3778e+00],\n        [2.2556e+00, 1.2638e-01, 6.0428e+00, 1.1526e+00],\n        [0.0000e+00, 4.2276e-02, 9.4557e-01, 3.3438e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.5042, 0.3770, 0.3763, 0.3743, 0.3128, 0.1388, 0.0737],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[  0.0000, 220.8891,   1.8068, 223.6330],\n        [  0.0000, 221.4408,   0.7506, 223.7735]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2620, 0.1477], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5534, 0.2878, 0.5690, 0.2969]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0352, 0.1680, 0.1068, 0.2344]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2461, 0.2565, 0.5286, 0.6146]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7760, 0.5990, 0.7852, 0.6172],\n        [0.9596, 0.9844, 0.9714, 0.9935]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7786, 0.4453, 0.8372, 0.4701]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5820, 0.2292, 0.5924, 0.2474],\n        [0.0078, 0.9206, 0.0156, 0.9401]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.2812, 0.4284, 0.3607, 0.4544]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4987, 0.1654, 0.6120, 0.3073]]), 'labels': tensor([1])}]\nbatch 1\nout :\n [{'boxes': tensor([[0.0000e+00, 1.0863e-03, 1.1726e+00, 1.0409e+00],\n        [0.0000e+00, 0.0000e+00, 4.3652e-01, 1.3785e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1875, 0.1601], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 7.5893e-02, 1.1664e+00, 1.9675e+00],\n        [0.0000e+00, 5.8319e-02, 4.9625e-01, 2.0897e+00],\n        [0.0000e+00, 3.2563e-02, 8.6410e-01, 7.9334e-01],\n        [0.0000e+00, 6.7311e-01, 1.9304e+00, 7.0782e+00],\n        [0.0000e+00, 4.9981e-01, 2.7367e+00, 4.6198e+00],\n        [2.2276e+02, 2.6444e-01, 2.2381e+02, 3.2617e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.4792, 0.3341, 0.1490, 0.0966, 0.0619, 0.0543],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0121, 2.0365, 0.3367],\n        [0.0000, 0.0000, 1.1885, 1.2110],\n        [0.0000, 0.0000, 0.1179, 1.4816],\n        [0.0000, 0.0000, 0.7355, 0.8697],\n        [0.0000, 0.0000, 0.9420, 2.9003]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.3847, 0.3410, 0.2680, 0.2551, 0.1410], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.1491e+00, 1.7566e+00],\n        [2.2175e+02, 2.5079e-02, 2.2373e+02, 1.9842e+00],\n        [0.0000e+00, 0.0000e+00, 4.9078e-01, 1.6030e+00],\n        [0.0000e+00, 2.9011e-02, 2.0116e+00, 1.1455e+00],\n        [0.0000e+00, 0.0000e+00, 7.9698e-01, 8.3486e-01],\n        [2.2244e+02, 8.1108e-01, 2.2395e+02, 9.9294e+00],\n        [0.0000e+00, 2.9409e-02, 2.8462e+00, 1.9223e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.1468, 0.1126, 0.0871, 0.0851, 0.0780, 0.0518, 0.0501],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.0383e-02, 3.1457e-01, 1.6348e+00],\n        [3.5381e-05, 1.5234e-02, 9.7295e-01, 9.4449e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.4554, 0.3264], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0101, 2.0446, 0.3127],\n        [0.0000, 0.0000, 1.2711, 1.2004],\n        [0.0000, 0.0000, 0.2106, 1.5970],\n        [0.0000, 0.0000, 1.0555, 2.7960],\n        [0.0000, 0.0000, 0.7562, 0.9134],\n        [0.0000, 0.3505, 3.0516, 4.6981]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.4640, 0.4538, 0.3472, 0.2989, 0.2824, 0.0601],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0115, 0.0000, 1.4325, 2.1636],\n        [0.0072, 0.0000, 0.5555, 1.9196],\n        [0.0140, 0.0000, 0.8895, 0.8500],\n        [0.0000, 0.0814, 2.9195, 2.2955],\n        [1.1217, 0.1065, 4.7489, 1.5715]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.3946, 0.2103, 0.1755, 0.1665, 0.0962], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.1523, 0.0482, 0.1823, 0.0638]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0885, 0.3372, 0.1094, 0.3594]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4635, 0.4466, 0.4766, 0.4609]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0560, 0.8880, 0.0872, 0.9089]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5703, 0.6706, 0.7786, 0.7279]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4518, 0.8034, 0.4701, 0.8112]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0404, 0.2565, 0.0482, 0.2630]]), 'labels': tensor([1])}]\nbatch 2\nout :\n [{'boxes': tensor([[0.0000, 0.0930, 1.3786, 1.9902]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.8351], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.3445, 1.7037],\n        [0.0000, 0.0000, 0.2776, 1.7044]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.3407, 0.1742], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0199, 0.0257, 1.2364, 2.5042]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.3063], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0419, 0.6298, 1.7714],\n        [0.0000, 0.0369, 1.0960, 1.3533]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.5967, 0.5854], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.7057, 0.4857, 0.8151, 0.5352]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5208, 0.0755, 0.5456, 0.1003],\n        [0.1784, 0.2852, 0.1927, 0.3008],\n        [0.2513, 0.7969, 0.2643, 0.8099]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.3789, 0.5221, 0.4219, 0.5495]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7161, 0.7122, 0.7604, 0.7266]]), 'labels': tensor([1])}]\nbatch 3\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.2338, 1.6415],\n        [0.0000, 0.0000, 0.3697, 1.9487],\n        [0.0000, 0.0413, 2.0553, 1.0253],\n        [0.0000, 0.0000, 0.8549, 0.8917],\n        [0.0000, 0.0000, 1.0516, 3.0920],\n        [0.0000, 0.1097, 2.7271, 2.3518],\n        [1.2328, 0.1015, 4.6222, 0.9648]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3407, 0.2217, 0.1979, 0.1539, 0.1236, 0.1222, 0.0900],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.3580, 1.7476],\n        [0.0000, 0.0000, 1.0540, 1.5707]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2696, 0.2219], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0363, 1.9925, 0.6740],\n        [0.0000, 0.0000, 0.2951, 1.7542],\n        [0.0000, 0.0000, 0.9950, 1.3895],\n        [0.0000, 0.0235, 0.7060, 3.0251]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.1820, 0.1743, 0.1661, 0.0793], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0242, 0.0408, 1.1662, 2.2835]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.4081], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 6.1710e-02, 2.2417e+00, 1.6237e+00],\n        [2.7094e-03, 2.5879e-03, 8.5196e-01, 8.1960e-01],\n        [0.0000e+00, 8.7185e-04, 7.9908e-01, 1.7372e+00],\n        [7.8694e-01, 7.1118e-02, 4.6056e+00, 1.2397e+00],\n        [2.2260e+02, 2.3480e+00, 2.2391e+02, 6.0355e+00],\n        [2.2230e+02, 1.0767e+00, 2.2389e+02, 4.5498e+00],\n        [0.0000e+00, 3.2841e+00, 3.1320e-01, 8.6812e+00],\n        [0.0000e+00, 9.5902e-02, 1.2764e+00, 3.1679e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2489, 0.1656, 0.1467, 0.1178, 0.0921, 0.0904, 0.0728, 0.0658],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0906, 1.4303, 2.7266]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.3802], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.4415e-01, 9.7840e-01, 2.2300e+00],\n        [3.7715e+00, 0.0000e+00, 1.0859e+01, 2.8209e+00],\n        [2.2172e+02, 2.2055e+02, 2.2363e+02, 2.2365e+02]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.2499, 0.1932, 0.1204], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.4677e-02, 1.2297e+00, 1.4772e+00],\n        [0.0000e+00, 0.0000e+00, 3.5156e-01, 1.7119e+00],\n        [0.0000e+00, 2.6958e-03, 6.5422e-01, 6.7413e-01],\n        [0.0000e+00, 3.8934e-02, 2.0260e+00, 7.8392e-01],\n        [0.0000e+00, 0.0000e+00, 9.8546e-01, 2.9684e+00],\n        [0.0000e+00, 8.9475e-02, 2.8664e+00, 1.9610e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3381, 0.2504, 0.2052, 0.1796, 0.1280, 0.0978],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0066, 1.2275, 1.2523],\n        [0.0000, 0.0000, 0.3420, 1.6588]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.3110, 0.2085], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0274, 1.3688, 1.8090],\n        [0.0000, 0.0000, 0.5833, 1.7478],\n        [0.0000, 0.0000, 0.7182, 0.7914],\n        [0.0000, 0.0325, 2.1475, 1.2605]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.2290, 0.1058, 0.0771, 0.0603], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.6901, 0.4245, 0.6979, 0.4388],\n        [0.6432, 0.5312, 0.6953, 0.6328]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.6237, 0.7591, 0.6341, 0.7656]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3672, 0.8086, 0.4062, 0.8320]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0273, 0.7760, 0.0482, 0.7995]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1172, 0.6159, 0.3542, 0.7786]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6484, 0.9245, 0.7096, 0.9661],\n        [0.8333, 0.8854, 0.8919, 0.9271]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.9987, 0.8320, 1.0000, 0.8477]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8711, 0.0156, 0.8906, 0.0755],\n        [0.4583, 0.3477, 0.5026, 0.3958],\n        [0.3529, 0.1146, 0.3646, 0.1341],\n        [0.3398, 0.0599, 0.3594, 0.0781],\n        [0.9987, 0.5560, 1.0000, 0.6003],\n        [0.3281, 0.0833, 0.3633, 0.1536]]), 'labels': tensor([1, 1, 1, 1, 1, 1])}, {'boxes': tensor([[0.9987, 0.0312, 1.0000, 0.0443]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9349, 0.8060, 0.9961, 1.0000],\n        [0.1471, 0.2422, 0.1667, 0.2500],\n        [0.8190, 0.3945, 0.9010, 0.4609],\n        [0.1237, 0.5651, 0.3281, 0.6680]]), 'labels': tensor([1, 1, 1, 1])}]\nbatch 4\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.3799, 2.0461],\n        [0.0000, 0.0400, 2.2749, 1.5229],\n        [0.0000, 0.0000, 0.4462, 2.0008],\n        [0.0000, 0.0000, 0.8835, 0.8590]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.5630, 0.4804, 0.3854, 0.3104], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0234, 1.4656, 1.9279],\n        [0.0000, 0.0000, 0.7112, 1.7575]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2136, 0.1069], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.2693, 1.6092]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.3769], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[2.2202e+02, 1.0986e+00, 2.2379e+02, 6.1273e+00],\n        [0.0000e+00, 9.6142e-02, 1.0769e+00, 2.2181e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.0645, 0.0553], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.6380, 0.0208, 0.8932, 0.2214]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4453, 0.5651, 0.4648, 0.5885]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7487, 0.7292, 0.9518, 0.7956],\n        [0.3984, 0.3307, 0.4727, 0.3633]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7474, 0.8164, 0.9987, 0.9531],\n        [0.5846, 0.6315, 0.8776, 0.7891],\n        [0.7734, 0.4753, 0.9922, 0.5872],\n        [0.9987, 0.2943, 1.0000, 0.3372]]), 'labels': tensor([1, 1, 1, 1])}]\nbatch 5\nout :\n [{'boxes': tensor([[0.0000, 0.0110, 1.9935, 0.3903],\n        [0.0000, 0.0000, 1.1282, 1.2428],\n        [0.0000, 0.0463, 2.6525, 1.7887],\n        [0.0000, 0.0000, 0.1721, 1.5765],\n        [1.1339, 0.0074, 4.4925, 0.0849],\n        [0.0000, 0.0000, 0.8549, 2.9056]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3222, 0.2314, 0.2199, 0.1855, 0.1718, 0.0884],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 6.4734e-02, 2.1603e+00, 1.4168e+00],\n        [0.0000e+00, 3.9289e-03, 1.1830e+00, 1.9693e+00],\n        [0.0000e+00, 6.3386e-04, 9.2953e-01, 9.0456e-01],\n        [0.0000e+00, 0.0000e+00, 5.8025e-01, 1.9209e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.5238, 0.4527, 0.3347, 0.3261], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1021, 1.2526, 1.2945],\n        [0.0000, 0.1919, 1.1851, 2.2711],\n        [0.0000, 0.2448, 2.3479, 1.9585],\n        [0.0000, 0.3005, 0.8105, 3.3651]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.5747, 0.5452, 0.3193, 0.1117], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 6.8451e-02, 1.0957e+00, 2.2654e+00],\n        [2.2249e+02, 1.7182e+00, 2.2383e+02, 6.2183e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2102, 0.1305], grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 4.1901e-02, 2.0438e+00, 1.0205e+00],\n        [0.0000e+00, 0.0000e+00, 1.1450e+00, 1.7189e+00],\n        [0.0000e+00, 0.0000e+00, 2.6855e-01, 1.7133e+00],\n        [0.0000e+00, 3.6329e-04, 8.3554e-01, 8.8142e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.2693, 0.2440, 0.1937, 0.1380], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.2956, 1.6763],\n        [0.0000, 0.0573, 2.2348, 1.1080],\n        [0.0000, 0.0000, 0.4595, 1.9760],\n        [0.0000, 0.0000, 0.8349, 0.8134],\n        [0.0654, 0.0683, 3.5985, 1.3361],\n        [0.0000, 0.1268, 3.0679, 2.3351],\n        [1.2272, 0.1043, 4.8974, 1.0290],\n        [0.0000, 0.0000, 1.1100, 3.0856]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.4099, 0.2336, 0.2286, 0.1888, 0.1729, 0.1460, 0.1171, 0.1081],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0386, 1.1733, 1.2634],\n        [0.0000, 0.0299, 0.5793, 1.6640]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1366, 0.1073], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0058, 0.0000, 1.1790, 1.6830],\n        [0.0041, 0.0000, 0.4581, 1.7011],\n        [0.0103, 0.0000, 0.8963, 0.8974]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.1809, 0.1341, 0.0765], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.2930, 0.8099, 0.3008, 0.8203]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4102, 0.7344, 0.4518, 0.7708],\n        [0.1940, 0.8490, 0.2383, 0.8841]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.8372, 0.3503, 0.8568, 0.3750]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1810, 0.1146, 0.1992, 0.1276]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4857, 0.8372, 0.7292, 1.0000]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5391, 0.8164, 0.6914, 0.8906],\n        [0.7096, 0.8294, 0.8164, 0.8750],\n        [0.6237, 0.6875, 0.7057, 0.7435],\n        [0.7096, 0.8672, 0.8398, 0.9115]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.2786, 0.5964, 0.2969, 0.6146],\n        [0.1784, 0.3086, 0.2148, 0.3398],\n        [0.0742, 0.7279, 0.1276, 0.7656]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.1745, 0.8164, 0.2643, 0.8620]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0469, 0.7083, 0.1276, 0.8438]]), 'labels': tensor([1])}]\nbatch 6\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.3102, 2.1302],\n        [0.0000, 0.0000, 0.5632, 1.9554]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.4601, 0.3119], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 5.2610e-02, 1.1981e+00, 1.6555e+00],\n        [0.0000e+00, 3.4038e-02, 5.0404e-01, 1.6465e+00],\n        [4.7217e-03, 5.5194e-02, 9.9503e-01, 2.9849e+00],\n        [0.0000e+00, 1.1232e-01, 2.6757e+00, 1.8367e+00],\n        [1.8439e-03, 3.5293e-02, 9.4687e-01, 9.8535e-01],\n        [0.0000e+00, 8.0924e-02, 2.0500e+00, 9.9074e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2464, 0.1731, 0.1463, 0.1192, 0.1063, 0.0999],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 4.5367e-02, 1.1085e+00, 1.6716e+00],\n        [2.2253e+02, 1.7880e+00, 2.2397e+02, 6.3242e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2588, 0.0591], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0140, 1.4025, 1.7729],\n        [0.0000, 0.0000, 0.5258, 1.6202],\n        [0.0000, 0.0300, 2.1233, 1.0471],\n        [0.0000, 0.0000, 0.7411, 0.8061],\n        [0.0000, 0.0290, 2.8487, 2.1187]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.2898, 0.1411, 0.1169, 0.1112, 0.0841], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.2012, 1.7671],\n        [0.0000, 0.0543, 2.0252, 1.1677],\n        [0.0000, 0.0000, 0.3504, 1.8438],\n        [0.0000, 0.0000, 0.8122, 0.7961],\n        [0.0037, 0.0000, 0.9737, 3.3140]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.2704, 0.1797, 0.1698, 0.1531, 0.0973], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.3935, 2.1130],\n        [0.0000, 0.0000, 1.0153, 1.0575],\n        [0.0000, 0.0758, 2.1065, 1.3629]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.1948, 0.1940, 0.1149], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5885, 0.6680, 0.7083, 0.7292]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5456, 0.4049, 0.5573, 0.4141]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0156, 0.4661, 0.2969, 0.5534]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5182, 0.6745, 0.5365, 0.6914],\n        [0.0898, 0.8151, 0.1198, 0.8451]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.5768, 0.0794, 0.6120, 0.1836],\n        [0.6042, 0.0729, 0.6263, 0.1536]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.2474, 0.8932, 0.2812, 0.9193],\n        [0.0677, 0.2305, 0.0885, 0.2500],\n        [0.0299, 0.9779, 0.0560, 1.0000]]), 'labels': tensor([1, 1, 1])}]\nbatch 7\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.1438, 1.4439],\n        [0.0000, 0.0000, 0.2420, 1.7197]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2181, 0.2059], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 3.8862e-03, 1.2594e+00, 1.8322e+00],\n        [0.0000e+00, 3.2072e-02, 2.0401e+00, 1.2666e+00],\n        [1.0011e+00, 7.9915e-02, 4.6656e+00, 1.0981e+00],\n        [0.0000e+00, 3.9374e-02, 2.7072e+00, 2.0195e+00],\n        [0.0000e+00, 0.0000e+00, 4.0795e-01, 1.6435e+00],\n        [0.0000e+00, 0.0000e+00, 7.9691e-01, 7.4104e-01],\n        [0.0000e+00, 1.8531e-01, 2.9099e+00, 4.6510e+00],\n        [2.2525e+00, 4.7674e-02, 6.0523e+00, 5.7797e-01],\n        [0.0000e+00, 3.7747e-01, 3.0365e+00, 9.1312e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3743, 0.2390, 0.2242, 0.2195, 0.1953, 0.1650, 0.1079, 0.0897, 0.0606],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.3045, 1.9179],\n        [0.0000, 0.0000, 0.5542, 1.7216]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.5090, 0.2937], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0416, 1.2615, 1.6961],\n        [0.0000, 0.0221, 0.5060, 1.7374]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.5441, 0.4166], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0600, 1.5660, 2.2723],\n        [0.0000, 0.0000, 0.6794, 1.8006],\n        [0.0000, 0.0000, 0.8143, 0.7123]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.1855, 0.1038, 0.0744], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2013, 1.5532, 2.6791],\n        [0.0000, 0.0795, 0.7047, 2.1640]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2847, 0.0899], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.4466, 0.6055, 0.5820, 0.6523]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3737, 0.9154, 0.3906, 0.9310]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0638, 0.2604, 0.0846, 0.2917]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6263, 0.5495, 0.6992, 0.6081],\n        [0.6133, 0.5664, 0.6953, 0.6302]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.9375, 0.5104, 0.9987, 0.5521],\n        [0.9674, 0.5013, 0.9922, 0.5208],\n        [0.2135, 0.2409, 0.2656, 0.2721],\n        [0.9609, 0.5260, 0.9987, 0.5508],\n        [0.2826, 0.6393, 0.3555, 0.6771]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.8008, 0.8776, 0.8216, 0.8945],\n        [0.4427, 0.0078, 0.4570, 0.0273],\n        [0.3229, 0.0143, 0.5820, 0.2617]]), 'labels': tensor([1, 1, 1])}]\nbatch 8\nout :\n [{'boxes': tensor([[0.0000e+00, 6.3334e-02, 1.5637e+00, 2.1610e+00],\n        [0.0000e+00, 0.0000e+00, 8.7654e-01, 1.8502e+00],\n        [0.0000e+00, 1.0925e-03, 8.2480e-01, 7.4853e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.1665, 0.0879, 0.0609], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1057, 2.1550, 2.0063],\n        [0.0000, 0.0000, 0.9192, 1.0637]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1373, 0.0900], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.2199e-01, 2.4957e+00, 1.8669e+00],\n        [2.2395e-03, 5.9521e-02, 1.1368e+00, 1.6905e+00],\n        [2.4382e-02, 1.0296e-01, 2.3227e+00, 1.0689e+00],\n        [0.0000e+00, 4.9068e-02, 2.9398e-01, 1.7486e+00],\n        [0.0000e+00, 1.3798e-01, 8.9402e-01, 3.3312e+00],\n        [2.2244e+02, 1.9816e+00, 2.2391e+02, 5.6194e+00],\n        [1.2010e+00, 8.9854e-02, 4.6466e+00, 5.0484e-01],\n        [2.2236e+02, 1.5999e+00, 2.2386e+02, 9.1039e+00],\n        [0.0000e+00, 6.3773e-01, 3.5025e+00, 9.1941e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.5638, 0.4669, 0.3814, 0.3772, 0.1567, 0.1304, 0.1292, 0.1004, 0.0623],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 3.1672e-02, 1.1323e+00, 2.4875e+00],\n        [2.2194e+02, 4.3013e-01, 2.2373e+02, 3.5883e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1616, 0.1273], grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0707, 1.3935, 1.8091],\n        [0.0000, 0.0209, 0.5332, 1.6548]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2055, 0.1010], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.3076, 1.6399],\n        [0.0000, 0.0000, 0.9232, 1.3947],\n        [0.0000, 0.2824, 2.8123, 4.8446]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.3565, 0.3044, 0.0700], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5247, 0.2383, 0.5378, 0.2513]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0781, 0.6758, 0.0951, 0.6901]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6628, 0.7474, 0.6745, 0.7747]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1445, 0.5404, 0.4258, 0.6784]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5755, 0.1615, 0.6133, 0.1992]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2591, 0.8633, 0.2865, 0.8763],\n        [0.9076, 0.6172, 0.9141, 0.6432],\n        [0.6875, 0.8047, 0.6992, 0.8125]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.6198, 0.1445, 0.7695, 0.2161]]), 'labels': tensor([1])}]\nbatch 9\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.3256, 2.2556],\n        [0.0000, 0.0000, 0.5557, 2.0533]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2381, 0.1079], grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0089, 0.0000, 1.4260, 2.1730],\n        [0.0081, 0.0000, 0.7306, 1.9320],\n        [0.0000, 0.0334, 2.3533, 1.5645],\n        [0.0061, 0.0000, 0.8456, 0.8184]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.2312, 0.1220, 0.1177, 0.0972], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.4409, 2.1272],\n        [0.0000, 0.0000, 0.6936, 1.7662],\n        [0.8868, 0.0681, 4.7616, 1.7391],\n        [0.0000, 0.0000, 0.7616, 0.7796],\n        [2.0329, 0.0801, 6.1549, 1.4780]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.1802, 0.0814, 0.0775, 0.0604, 0.0522], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.8499, 1.8300],\n        [0.0000, 0.0000, 0.3019, 2.0352],\n        [0.0000, 0.0482, 1.9969, 1.0626]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.2065, 0.2010, 0.1427], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[1.0298e-02, 0.0000e+00, 1.2010e+00, 1.9581e+00],\n        [0.0000e+00, 7.5991e-02, 3.0358e+00, 2.3394e+00],\n        [5.7496e-03, 0.0000e+00, 6.1272e-01, 1.9011e+00],\n        [0.0000e+00, 5.6355e-02, 2.1050e+00, 1.3682e+00],\n        [1.3054e+00, 1.3381e-01, 4.9306e+00, 1.6074e+00],\n        [7.1132e-03, 0.0000e+00, 9.3816e-01, 9.0503e-01],\n        [2.4761e+00, 1.2090e-01, 6.1066e+00, 1.1143e+00],\n        [1.7576e+00, 1.6195e-01, 7.5015e+00, 1.4214e+00],\n        [1.4100e-02, 3.0623e-01, 3.0973e+00, 5.0241e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.5709, 0.5259, 0.4580, 0.4436, 0.4079, 0.2561, 0.1467, 0.0823, 0.0735],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0667, 1.3294, 1.7676],\n        [0.0000, 0.0157, 0.6606, 1.5634],\n        [0.0000, 0.0116, 0.8508, 0.8803],\n        [0.0000, 0.0743, 1.0237, 2.9607],\n        [0.0000, 0.0594, 2.1106, 1.1323]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.1664, 0.0812, 0.0647, 0.0630, 0.0544], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0379, 2.5485, 1.8506],\n        [0.0000, 0.0144, 1.9754, 0.4413],\n        [0.0000, 0.0000, 0.9133, 2.8278],\n        [0.0000, 0.0034, 1.1870, 1.3088],\n        [0.0000, 0.0000, 0.2479, 1.5014],\n        [0.0000, 0.0000, 0.7601, 0.8236]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2683, 0.2679, 0.2480, 0.2277, 0.1859, 0.1441],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.5414e+00, 2.0621e+00],\n        [4.1747e-04, 0.0000e+00, 4.7655e-01, 1.9709e+00],\n        [0.0000e+00, 7.4185e-02, 2.6781e+00, 2.4627e+00],\n        [4.7159e-03, 0.0000e+00, 7.3395e-01, 7.6150e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.1759, 0.0850, 0.0715, 0.0531], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.3763, 0.3203, 0.4023, 0.3372],\n        [0.3971, 0.4245, 0.5143, 0.4609],\n        [0.3164, 0.3216, 0.3789, 0.3503]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.7253, 0.1419, 0.7747, 0.2513]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1146, 0.5560, 0.1432, 0.5807],\n        [0.8815, 0.4310, 0.8958, 0.4440]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.5404, 0.2500, 0.5586, 0.2708]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7214, 0.0000, 0.8724, 0.0794]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0404, 0.7826, 0.0651, 0.7982]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3854, 0.1836, 0.4141, 0.2018]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4323, 0.0469, 0.4557, 0.0807],\n        [0.4206, 0.0534, 0.4479, 0.0872]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.8997, 0.0964, 0.9271, 0.1302]]), 'labels': tensor([1])}]\nbatch 10\nout :\n [{'boxes': tensor([[0.0000, 0.0534, 2.5169, 1.8064],\n        [0.0000, 0.0000, 1.2195, 1.5451],\n        [0.0000, 0.0271, 2.1025, 0.7663],\n        [0.9920, 0.0400, 4.4524, 0.6116],\n        [0.0000, 0.0000, 0.8786, 2.7930],\n        [0.0000, 0.0000, 0.3311, 1.5081],\n        [0.0000, 0.0000, 0.8175, 0.8269],\n        [2.4598, 0.0107, 5.8592, 0.1798]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3034, 0.2898, 0.2860, 0.2010, 0.1955, 0.1907, 0.1623, 0.0615],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.2141, 1.8610],\n        [0.0000, 0.0366, 2.0700, 1.2508],\n        [0.0000, 0.0000, 0.4653, 1.9341],\n        [0.0000, 0.0000, 0.8470, 0.8225],\n        [0.0000, 0.0724, 2.9630, 2.3423]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.3606, 0.3004, 0.2529, 0.2035, 0.1474], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0132, 1.3508, 1.7887],\n        [0.0000, 0.0000, 0.5036, 1.7512],\n        [0.9375, 0.0634, 4.6392, 0.9464],\n        [0.0000, 0.2717, 2.3514, 7.3034],\n        [0.0000, 0.0000, 0.7173, 0.7749],\n        [0.0000, 0.0453, 2.1034, 1.1112],\n        [2.2050, 0.0306, 6.0052, 0.4439],\n        [0.0000, 0.0591, 2.8027, 2.1233]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2089, 0.1107, 0.1094, 0.0938, 0.0857, 0.0734, 0.0534, 0.0519],\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.0599, 0.6406, 0.1432, 0.6992]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4362, 0.0859, 0.4440, 0.0951],\n        [0.5430, 0.2461, 0.5820, 0.2734]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.5781, 0.6133, 0.7396, 0.7682]]), 'labels': tensor([1])}]\nbatch 11\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.0953, 0.9746],\n        [0.0000, 0.0000, 0.1788, 1.3936]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2080, 0.1961], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2624, 1.2114, 1.8345]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.2104], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[61.9215,  0.1196, 65.9507,  1.5642],\n        [60.9098,  0.2105, 65.0561,  2.1561],\n        [57.0615,  2.0951, 64.7209,  6.6311],\n        [ 0.0000,  0.1059,  1.1599,  1.1500],\n        [ 0.0000,  0.3380,  1.3396,  2.8108],\n        [ 0.0000,  0.1823,  0.8742,  2.2321]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2976, 0.2871, 0.2272, 0.1154, 0.1101, 0.0834],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.4069, 1.8821],\n        [0.0000, 0.0722, 2.3351, 2.1556],\n        [0.0000, 0.0000, 0.8174, 1.6056],\n        [0.0000, 0.0445, 1.9408, 0.8613],\n        [1.2917, 0.0654, 4.8027, 0.4812]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.1529, 0.1389, 0.1341, 0.1001, 0.0571], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0932, 0.7701, 1.7751]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.2843], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5911, 0.4479, 0.6354, 0.4727],\n        [0.5885, 0.4388, 0.6302, 0.4622]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7956, 0.8984, 0.8737, 0.9609],\n        [0.1003, 0.8711, 0.2188, 0.9661],\n        [0.7904, 0.9102, 0.8841, 0.9857],\n        [0.8099, 0.9453, 0.8594, 0.9883]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.2135, 0.6836, 0.3724, 0.8854],\n        [0.2982, 0.7943, 0.3177, 0.8190],\n        [0.2292, 0.7188, 0.3060, 0.8151],\n        [0.7734, 0.5508, 0.9987, 0.8438]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.3646, 0.6523, 0.7057, 0.8333]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7839, 0.8620, 0.8060, 0.8854],\n        [0.1003, 0.4492, 0.1315, 0.4805],\n        [0.0456, 0.3737, 0.1198, 0.4596],\n        [0.8034, 0.8750, 0.8581, 0.9258]]), 'labels': tensor([1, 1, 1, 1])}]\nbatch 12\nout :\n [{'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.3193e+00, 1.9646e+00],\n        [0.0000e+00, 4.1994e-02, 2.1730e+00, 1.3744e+00],\n        [0.0000e+00, 6.3954e-02, 2.7665e+00, 2.3356e+00],\n        [2.0209e-03, 0.0000e+00, 3.5108e-01, 1.8631e+00],\n        [7.2042e-03, 0.0000e+00, 8.0224e-01, 7.6316e-01],\n        [0.0000e+00, 2.5561e-01, 2.9779e+00, 4.7838e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3570, 0.2121, 0.2020, 0.1823, 0.1347, 0.0580],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.3062, 1.5357],\n        [0.0000, 0.0000, 0.3965, 1.6807],\n        [0.0000, 0.0304, 2.1165, 0.7441],\n        [0.0000, 0.0656, 2.9190, 2.0701],\n        [0.0000, 0.0000, 1.1020, 2.9328],\n        [0.0000, 0.0000, 0.8591, 0.8839],\n        [0.0369, 0.0623, 3.3732, 0.9586],\n        [1.3073, 0.0813, 4.6680, 0.7013]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3329, 0.2540, 0.2364, 0.2268, 0.2154, 0.1694, 0.1010, 0.0741],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.4916e+00, 2.1382e+00],\n        [1.8648e-03, 0.0000e+00, 6.2089e-01, 1.9202e+00],\n        [1.1382e-02, 0.0000e+00, 8.3963e-01, 8.6581e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.2011, 0.0923, 0.0610], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 3.3821e-03, 1.6218e+00, 2.2319e+00],\n        [0.0000e+00, 0.0000e+00, 7.8738e-01, 1.9347e+00],\n        [2.6822e-03, 0.0000e+00, 7.8396e-01, 8.0859e-01],\n        [2.2216e+02, 8.1513e-01, 2.2386e+02, 4.7052e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.1381, 0.0801, 0.0754, 0.0509], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.1767, 1.3690],\n        [0.0000, 0.0000, 0.3604, 1.7116]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.3288, 0.2698], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1372, 1.7509, 3.0739]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.1281], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.9741, 1.9887]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.1003], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 4.5967e-02, 1.2533e+00, 1.5261e+00],\n        [0.0000e+00, 8.5137e-02, 1.0906e+00, 3.4487e+00],\n        [0.0000e+00, 2.6222e-02, 6.3392e-01, 1.7977e+00],\n        [2.2236e+02, 1.7999e+00, 2.2383e+02, 6.3871e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.2212, 0.1227, 0.1117, 0.0532], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1624, 1.0887, 2.0572]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.1894], grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1095, 0.1885, 1.7368],\n        [0.0000, 0.0982, 1.0298, 1.2715]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2996, 0.1566], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.9987, 0.8802, 1.0000, 0.9206]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3880, 0.4154, 0.5690, 0.5729]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9688, 0.7474, 0.9935, 0.7721]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3294, 0.4987, 0.3724, 0.6003]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6354, 0.1576, 0.6471, 0.1706]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5781, 0.9089, 0.6875, 0.9466]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2109, 0.9518, 0.3138, 1.0000]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5078, 0.2799, 0.5404, 0.3073],\n        [0.2409, 0.7734, 0.4284, 0.9362],\n        [0.3477, 0.1823, 0.4440, 0.2513]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.3060, 0.0612, 0.3073, 0.0625],\n        [0.3138, 0.0690, 0.4258, 0.1159],\n        [0.3060, 0.0495, 0.3294, 0.0599],\n        [0.3320, 0.0404, 0.3490, 0.0521]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.0898, 0.8620, 0.1094, 0.8815]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2266, 0.1836, 0.2513, 0.2135]]), 'labels': tensor([1])}]\nbatch 13\nout :\n [{'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.2731e+00, 1.7356e+00],\n        [0.0000e+00, 5.5094e-02, 2.9966e+00, 1.7336e+00],\n        [0.0000e+00, 3.4221e-02, 2.2413e+00, 9.3459e-01],\n        [1.9509e-03, 0.0000e+00, 4.3366e-01, 1.4531e+00],\n        [6.8618e-03, 0.0000e+00, 8.3398e-01, 8.5307e-01],\n        [1.1215e-02, 7.6879e-03, 1.0753e+00, 3.3459e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2952, 0.2908, 0.2675, 0.1563, 0.1327, 0.0926],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0729, 0.6798, 1.8428]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.3040], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.2662, 1.5790],\n        [0.0000, 0.0270, 2.1057, 0.8768],\n        [0.0000, 0.0000, 0.2945, 1.8260],\n        [0.0000, 0.0000, 0.7948, 0.8463],\n        [0.0000, 0.0000, 1.0409, 3.0644]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.3443, 0.2438, 0.2318, 0.1854, 0.1705], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.3751, 1.8278],\n        [0.0000, 0.0000, 0.5054, 1.7903],\n        [0.0000, 0.0856, 2.8954, 2.1342],\n        [0.0000, 0.0000, 0.8831, 0.8647],\n        [0.0000, 0.0546, 2.1663, 1.2143]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.3003, 0.1668, 0.1221, 0.1150, 0.1132], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.2713, 1.5363],\n        [0.0000, 0.0000, 0.3867, 1.8309],\n        [0.0000, 0.0331, 2.1075, 0.7771],\n        [0.0000, 0.0703, 2.7438, 2.2147],\n        [0.0000, 0.0000, 1.0710, 3.0131],\n        [0.0000, 0.0000, 0.8525, 0.9196],\n        [0.1152, 0.0591, 3.3910, 0.8922]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3614, 0.2943, 0.2377, 0.2337, 0.2014, 0.1964, 0.1001],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 8.7686e-04, 1.3010e+00, 1.6464e+00],\n        [0.0000e+00, 0.0000e+00, 4.1436e-01, 1.7782e+00],\n        [0.0000e+00, 0.0000e+00, 8.5087e-01, 7.9596e-01],\n        [0.0000e+00, 5.3709e-02, 2.1438e+00, 9.6670e-01],\n        [0.0000e+00, 1.2482e-01, 2.8077e+00, 2.1029e+00],\n        [1.0522e+00, 8.9932e-02, 4.5439e+00, 8.5761e-01],\n        [2.2344e+00, 4.1601e-02, 5.9150e+00, 4.3856e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3193, 0.1696, 0.1642, 0.1459, 0.0709, 0.0640, 0.0584],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1040, 1.2304, 2.2743],\n        [0.0000, 0.0460, 1.1249, 1.0431],\n        [0.0047, 0.1033, 0.8898, 3.8710],\n        [0.0000, 0.1689, 2.3683, 1.9225],\n        [0.0000, 0.4352, 2.7623, 4.6214],\n        [0.6879, 0.2320, 4.5404, 2.0688]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.4266, 0.4226, 0.2067, 0.1910, 0.1335, 0.1120],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0078, 1.1461, 1.6074],\n        [0.0000, 0.0000, 0.5203, 1.5580]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2282, 0.1592], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1657, 1.4121, 1.2510]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.1927], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.6471, 0.3789, 0.6745, 0.4193],\n        [0.2474, 0.0677, 0.2799, 0.0885],\n        [0.2734, 0.0742, 0.3411, 0.1211],\n        [0.1901, 0.1289, 0.1966, 0.1458]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.8945, 0.6029, 0.9258, 0.6237]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8763, 0.5130, 0.9297, 0.5430],\n        [0.6341, 0.7266, 0.6992, 0.7656]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.4492, 0.0495, 0.5273, 0.1003],\n        [0.3008, 0.0625, 0.4466, 0.1615]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.3672, 0.7148, 0.4635, 0.7799],\n        [0.0547, 0.8451, 0.1523, 0.9115]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.3516, 0.8971, 0.3685, 0.9128]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6406, 0.0599, 0.6628, 0.0690]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2201, 0.5221, 0.4245, 0.6901]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3789, 0.4440, 0.5443, 0.5195]]), 'labels': tensor([1])}]\nbatch 14\nout :\n [{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[3.4652e-02, 0.0000e+00, 8.6868e-01, 2.4091e+00],\n        [6.9146e-02, 6.6322e-02, 2.8929e+00, 1.8044e+00],\n        [1.2693e+00, 4.4578e-02, 4.5556e+00, 3.8362e-01],\n        [1.6649e-02, 0.0000e+00, 3.8840e-01, 1.5160e+00],\n        [6.1514e-04, 2.4227e+00, 3.6094e-02, 6.8962e+00],\n        [2.9468e-01, 4.4911e-02, 3.3680e+00, 5.8395e-01],\n        [3.7190e-02, 5.2371e-03, 2.0423e+00, 1.2588e-01],\n        [4.5115e-02, 0.0000e+00, 1.1521e+00, 1.1258e+00],\n        [3.2400e-02, 0.0000e+00, 7.2073e-01, 9.2014e-01],\n        [2.1716e+02, 6.8366e-02, 2.2291e+02, 8.8700e-01],\n        [1.1516e-01, 3.3094e-01, 3.2564e+00, 4.9960e+00],\n        [5.9155e-01, 1.6259e-01, 6.2183e+00, 1.3348e+00],\n        [2.1553e+02, 4.3938e-02, 2.2130e+02, 6.5633e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.5981, 0.3846, 0.3374, 0.3067, 0.2851, 0.2626, 0.2516, 0.2397, 0.1995,\n        0.1431, 0.1224, 0.0920, 0.0688], grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.8372, 0.3177, 0.8659, 0.3398]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4922, 0.0000, 0.7943, 0.2214]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9479, 0.8424, 0.9805, 0.8828]]), 'labels': tensor([1])}]\nbatch 15\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.2229, 1.4470],\n        [0.0000, 0.0000, 0.0185, 1.7625]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2462, 0.1589], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0528, 1.1764, 2.1627]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.8295], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.4523e-02, 2.0783e+00, 4.7075e-01],\n        [0.0000e+00, 0.0000e+00, 1.1985e+00, 1.2889e+00],\n        [1.9835e-03, 0.0000e+00, 9.2623e-01, 2.6009e+00],\n        [0.0000e+00, 3.8691e-02, 2.6717e+00, 1.8814e+00],\n        [0.0000e+00, 0.0000e+00, 2.9596e-01, 1.5692e+00],\n        [1.4224e-03, 0.0000e+00, 8.4269e-01, 8.9296e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3523, 0.3333, 0.3291, 0.3214, 0.2777, 0.2163],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 5.0739e-02, 1.4144e+00, 1.8295e+00],\n        [0.0000e+00, 1.3113e-02, 3.1682e-01, 1.8793e+00],\n        [0.0000e+00, 8.0746e-02, 2.3056e+00, 1.1583e+00],\n        [0.0000e+00, 1.4446e-02, 7.9955e-01, 8.0760e-01],\n        [0.0000e+00, 1.0746e-01, 1.1581e+00, 3.2338e+00],\n        [8.4323e-01, 1.1040e-01, 4.6504e+00, 1.0901e+00],\n        [2.2264e+02, 1.1803e+00, 2.2388e+02, 5.1663e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.6914, 0.4583, 0.4138, 0.4055, 0.3024, 0.2198, 0.0840],\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.8398, 0.0846, 0.9987, 0.2539],\n        [0.7005, 0.7148, 0.7904, 0.8099],\n        [0.3503, 0.0794, 0.4245, 0.1484],\n        [0.4089, 0.9271, 0.4987, 1.0000]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.5221, 0.0000, 0.5846, 0.0938],\n        [0.3294, 0.7461, 0.4570, 1.0000],\n        [0.4792, 0.0000, 0.6133, 0.2122]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.9544, 0.7005, 0.9844, 0.7318]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1549, 0.4492, 0.3320, 0.7734]]), 'labels': tensor([1])}]\nbatch 16\nout :\n [{'boxes': tensor([[0.0000, 0.0031, 1.0542, 0.8203],\n        [0.0000, 0.0000, 0.1737, 1.3626]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.2369, 0.2349], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0254, 1.3719, 1.9553],\n        [0.0000, 0.0000, 0.6580, 2.0327]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.5040, 0.2764], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0545, 0.6016, 2.7237],\n        [0.0000, 0.0276, 1.7898, 0.3119],\n        [0.0000, 0.0417, 0.2448, 1.3768],\n        [0.0000, 0.0422, 0.8907, 1.1722]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.1905, 0.1429, 0.1143, 0.0958], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[ 0.0000,  0.0826,  1.2824,  2.9110],\n        [ 0.0000,  0.4142,  3.0661, 10.9957],\n        [ 0.0000,  0.3254,  3.9988,  5.8613]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.9386, 0.0873, 0.0722], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.1836, 0.6094, 0.2266, 0.6341]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6094, 0.3737, 0.6393, 0.3997],\n        [0.0859, 0.4909, 0.1094, 0.5026],\n        [0.3346, 0.2266, 0.3971, 0.2409],\n        [0.0924, 0.5026, 0.1016, 0.5039],\n        [0.4297, 0.2318, 0.4805, 0.2565]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.4844, 0.6029, 0.4987, 0.6120]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7083, 0.8633, 0.7318, 0.8854]]), 'labels': tensor([1])}]\nbatch 17\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.4442, 2.0735],\n        [0.0000, 0.0000, 0.5983, 1.9445]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1654, 0.0813], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0114, 1.4202, 1.8107],\n        [0.0000, 0.0000, 0.5929, 1.6463]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1850, 0.0979], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5104, 0.5729, 0.7604, 0.7435]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1576, 0.2604, 0.1719, 0.2734]]), 'labels': tensor([1])}]\nbatch 18\nout :\n [{'boxes': tensor([[0.0000e+00, 1.6594e-01, 1.1753e+00, 3.0344e+00],\n        [2.2013e+02, 1.3910e-01, 2.2342e+02, 1.8336e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.1319, 0.1276], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[7.7006e-03, 0.0000e+00, 1.3665e+00, 2.2664e+00],\n        [5.8061e-03, 0.0000e+00, 4.1820e-01, 2.0029e+00],\n        [1.0839e+00, 7.3986e-02, 5.0547e+00, 1.9229e+00],\n        [1.7238e-02, 0.0000e+00, 8.5352e-01, 6.2945e-01],\n        [0.0000e+00, 3.8488e-02, 2.9273e+00, 2.3559e+00],\n        [2.1204e+00, 8.6861e-02, 6.2047e+00, 1.5289e+00],\n        [0.0000e+00, 2.0682e-01, 2.9544e+00, 4.8741e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.6575, 0.3995, 0.3932, 0.2667, 0.2649, 0.0846, 0.0653],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0302, 1.3471, 1.7630],\n        [0.8660, 0.0710, 4.6846, 1.1150],\n        [0.0000, 0.0000, 0.6960, 1.5588],\n        [0.0000, 0.0339, 2.1661, 1.1243],\n        [0.0000, 3.3303, 0.3281, 8.3889]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.1878, 0.0953, 0.0853, 0.0773, 0.0685], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[2.2247e+02, 3.4418e+00, 2.2388e+02, 7.8401e+00],\n        [2.2195e+02, 2.4629e+00, 2.2384e+02, 6.9140e+00],\n        [0.0000e+00, 1.1156e-01, 9.3366e-01, 2.9220e+00],\n        [9.4250e-01, 1.2063e-01, 4.3096e+00, 1.5946e+00],\n        [2.2252e+02, 2.0911e+00, 2.2387e+02, 5.7883e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1]), 'scores': tensor([0.3762, 0.1762, 0.1372, 0.0940, 0.0533], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[3.7650e-03, 0.0000e+00, 3.6343e-01, 1.9635e+00],\n        [8.6537e-04, 0.0000e+00, 9.7500e-01, 1.5089e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.5174, 0.3589], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.9089, 0.4375, 0.9232, 0.4505]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4727, 0.4232, 0.5117, 0.4661]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3555, 0.5169, 0.4740, 0.6419]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0990, 0.5977, 0.1536, 0.6224]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3945, 0.7917, 0.4792, 0.8190],\n        [0.7995, 0.7904, 0.8411, 0.8099]]), 'labels': tensor([1, 1])}]\nbatch 19\nout :\n [{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.1222e-01, 1.3850e+00, 2.5341e+00],\n        [2.2199e+02, 1.6513e-01, 2.2363e+02, 4.7269e+00],\n        [2.2127e+02, 2.1835e+02, 2.2363e+02, 2.2400e+02]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.4779, 0.4047, 0.0601], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0073, 1.3807, 1.8956],\n        [0.0000, 0.0000, 0.3389, 1.6633],\n        [0.0000, 0.0000, 0.7609, 0.6886],\n        [1.0945, 0.1088, 4.7685, 1.5392]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.5607, 0.3626, 0.3250, 0.0727], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.7161, 0.7956, 0.9857, 0.8542],\n        [0.6549, 0.8398, 0.9987, 0.9271]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.5703, 0.8516, 0.6576, 0.8815],\n        [0.0898, 0.1628, 0.1927, 0.3229],\n        [0.9245, 0.3438, 0.9518, 0.3711]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.8307, 0.9896, 0.8398, 1.0000]]), 'labels': tensor([1])}]\nbatch 20\nout :\n [{'boxes': tensor([[0.0000, 0.0396, 0.9852, 1.3647]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.0582], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.1369, 1.2550]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.3069], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[221.9637,   1.5517, 223.7659,   5.7291]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.0522], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1623, 1.3407, 2.5846]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.4937], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0580, 0.9930, 1.7642],\n        [0.0000, 0.0332, 0.9947, 0.9069],\n        [0.0000, 0.1147, 1.9743, 1.4864]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.5707, 0.3793, 0.0840], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 3.6103e-02, 9.9245e-01, 3.1440e+00],\n        [0.0000e+00, 1.2093e-01, 2.6887e+00, 2.2318e+00],\n        [0.0000e+00, 4.6365e-03, 3.8856e-01, 1.8374e+00],\n        [0.0000e+00, 1.4892e-02, 1.1215e+00, 1.6123e+00],\n        [0.0000e+00, 3.6014e-01, 2.9048e+00, 5.0517e+00],\n        [0.0000e+00, 7.8988e-02, 2.0092e+00, 9.5570e-01],\n        [0.0000e+00, 1.2914e-02, 8.4468e-01, 1.0275e+00],\n        [0.0000e+00, 6.9252e-01, 3.2994e+00, 8.6953e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3149, 0.2728, 0.2101, 0.2033, 0.1620, 0.1251, 0.1132, 0.0506],\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5872, 0.8385, 0.6068, 0.8607]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2708, 0.7500, 0.4753, 0.7891]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5560, 0.3854, 0.6628, 0.4596]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7891, 0.0872, 0.8659, 0.1823],\n        [0.7630, 0.0951, 0.8229, 0.1641]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.0547, 0.6328, 0.1576, 0.6615]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0924, 0.1654, 0.4609, 0.2669]]), 'labels': tensor([1])}]\nbatch 21\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.2405, 1.9444],\n        [0.0000, 0.0000, 0.3533, 1.9481]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.3789, 0.2670], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0112, 0.0000, 1.5020, 2.1232],\n        [0.0054, 0.0000, 0.6721, 1.9029],\n        [0.0220, 0.0000, 0.9312, 0.9004],\n        [0.0053, 0.0846, 3.0633, 2.3256]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.2926, 0.1569, 0.0928, 0.0747], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0692, 1.0782, 2.0458]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.0997], grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 4.3514e-02, 1.5679e+00, 2.1589e+00],\n        [7.3902e-01, 7.3357e-02, 4.6841e+00, 1.6118e+00],\n        [0.0000e+00, 0.0000e+00, 6.4212e-01, 1.8725e+00],\n        [0.0000e+00, 9.7305e-04, 7.8261e-01, 6.9951e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.1730, 0.0796, 0.0785, 0.0539], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.3714e-02, 1.3334e+00, 1.9737e+00],\n        [0.0000e+00, 0.0000e+00, 4.2871e-01, 1.8532e+00],\n        [0.0000e+00, 7.8560e-02, 2.6464e+00, 2.2256e+00],\n        [6.2260e-03, 2.3244e-03, 8.3997e-01, 8.1020e-01]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1]), 'scores': tensor([0.2303, 0.1367, 0.0855, 0.0836], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0201, 0.6372, 2.5018],\n        [0.0000, 0.0303, 2.0303, 0.4147],\n        [0.0000, 0.1128, 2.7611, 1.6632],\n        [0.0000, 0.0229, 1.0640, 1.2175],\n        [1.3052, 0.0412, 4.8986, 0.3605],\n        [0.0000, 0.0497, 3.5359, 0.6031]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3370, 0.2973, 0.2643, 0.2280, 0.1430, 0.1147],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 3.5676e-02, 1.3635e+00, 1.5755e+00],\n        [0.0000e+00, 6.1535e-03, 5.8585e-01, 1.4326e+00],\n        [0.0000e+00, 4.8434e-02, 2.0381e+00, 7.5661e-01],\n        [0.0000e+00, 5.9401e-02, 1.1228e+00, 2.8984e+00],\n        [0.0000e+00, 9.6314e-03, 9.3540e-01, 9.7190e-01],\n        [0.0000e+00, 1.1467e-01, 2.8603e+00, 1.8309e+00],\n        [0.0000e+00, 3.0243e+00, 3.6685e-01, 8.3070e+00]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.2408, 0.1320, 0.1224, 0.1214, 0.1062, 0.0853, 0.0758],\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.3099, 0.4661, 0.4141, 0.5781]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4479, 0.2227, 0.4766, 0.2474]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5560, 0.6693, 0.5742, 0.6862],\n        [0.6862, 0.5846, 0.7122, 0.6107]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.8307, 0.0612, 0.8646, 0.0807]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5807, 0.5130, 0.6589, 0.5612],\n        [0.4609, 0.5260, 0.6836, 0.6562],\n        [0.7461, 0.7682, 0.7591, 0.7747]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.9987, 0.0951, 1.0000, 0.1068]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6823, 0.9857, 0.6979, 1.0000],\n        [0.6016, 0.8047, 0.6159, 0.8203],\n        [0.5195, 0.7005, 0.5339, 0.7253]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.3164, 0.0000, 0.4245, 0.1250]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8685, 0.1471, 0.9036, 0.1875]]), 'labels': tensor([1])}]\nbatch 22\nout :\n [{'boxes': tensor([[0.0000, 0.0000, 1.4157, 2.1599],\n        [0.0000, 0.0000, 0.5231, 1.9542]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.4013, 0.2110], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1650, 1.1795, 1.9354]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.4458], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.3822, 1.9485],\n        [0.0000, 0.0000, 0.4320, 1.8371]], grad_fn=<StackBackward0>), 'labels': tensor([1, 1]), 'scores': tensor([0.3417, 0.1769], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.1228e-02, 2.1038e+00, 2.3584e-01],\n        [0.0000e+00, 0.0000e+00, 1.1409e+00, 1.2617e+00],\n        [0.0000e+00, 0.0000e+00, 4.8551e-01, 1.5876e+00],\n        [0.0000e+00, 0.0000e+00, 8.2114e-01, 2.6136e+00],\n        [0.0000e+00, 8.8827e-02, 3.0785e+00, 1.7734e+00],\n        [1.2188e+00, 4.3389e-02, 4.6935e+00, 3.8666e-01],\n        [0.0000e+00, 3.6130e-02, 3.4196e+00, 4.8635e-01],\n        [2.4609e+00, 4.4913e-03, 5.9807e+00, 4.4709e-02]],\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.3507, 0.2963, 0.2424, 0.1868, 0.1706, 0.1242, 0.0972, 0.0723],\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[ 0.0000,  4.7623,  1.5742, 12.7311]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.1816], grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1205, 1.4929, 2.0810]], grad_fn=<StackBackward0>), 'labels': tensor([1]), 'scores': tensor([0.0970], grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.4792, 0.5234, 0.5104, 0.5495]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7227, 0.6315, 0.8555, 0.6667]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3685, 0.9219, 0.3750, 0.9284]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3698, 0.4492, 0.3984, 0.4701]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7565, 0.5768, 0.7708, 0.5898]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8815, 0.3359, 0.9115, 0.3594]]), 'labels': tensor([1])}]\nbatch 23\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/model-trained\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.tar\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[31], line 26\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# inputs = inputs.to(device)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, output)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,targets)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py:105\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[1;32m    104\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpn(images, features, targets)\n\u001b[0;32m--> 105\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    108\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/roi_heads.py:761\u001b[0m, in \u001b[0;36mRoIHeads.forward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    758\u001b[0m     regression_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    759\u001b[0m     matched_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox_roi_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_head(box_features)\n\u001b[1;32m    763\u001b[0m class_logits, box_regression \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_predictor(box_features)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/ops/poolers.py:314\u001b[0m, in \u001b[0;36mMultiScaleRoIAlign.forward\u001b[0;34m(self, x, boxes, image_shapes)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscales \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_levels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscales, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_levels \u001b[38;5;241m=\u001b[39m _setup_scales(\n\u001b[1;32m    311\u001b[0m         x_filtered, image_shapes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonical_scale, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonical_level\n\u001b[1;32m    312\u001b[0m     )\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiscale_roi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_filtered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/ops/poolers.py:204\u001b[0m, in \u001b[0;36m_multiscale_roi_align\u001b[0;34m(x_filtered, boxes, output_size, sampling_ratio, scales, mapper)\u001b[0m\n\u001b[1;32m    201\u001b[0m idx_in_level \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(levels \u001b[38;5;241m==\u001b[39m level)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    202\u001b[0m rois_per_level \u001b[38;5;241m=\u001b[39m rois[idx_in_level]\n\u001b[0;32m--> 204\u001b[0m result_idx_in_level \u001b[38;5;241m=\u001b[39m \u001b[43mroi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_level_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrois_per_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torchvision\u001b[38;5;241m.\u001b[39m_is_tracing():\n\u001b[1;32m    213\u001b[0m     tracing_results\u001b[38;5;241m.\u001b[39mappend(result_idx_in_level\u001b[38;5;241m.\u001b[39mto(dtype))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/ops/roi_align.py:238\u001b[0m, in \u001b[0;36mroi_align\u001b[0;34m(input, boxes, output_size, spatial_scale, sampling_ratio, aligned)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _roi_align(\u001b[38;5;28minput\u001b[39m, rois, spatial_scale, output_size[\u001b[38;5;241m0\u001b[39m], output_size[\u001b[38;5;241m1\u001b[39m], sampling_ratio, aligned)\n\u001b[1;32m    237\u001b[0m _assert_has_ops()\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# TRAIN AGAIN\nimport pickle\n\ntrain_again = False\n\nif train_again:\n    model_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n    model = model_rcnn.to(device)\n    torch.compile(model)\n    optimizer = optim.Adam(params = model.parameters(), lr=0.01)\n    checkpoint = torch.load(os.path.join(model_filepath, \"model.tar\"))\n    model.load_state_dict(checkpoint['model_state_dict'])\n\n    # Carica i DataLoader\n    with open(os.path.join(model_filepath, 'train_loader.pkl'), 'rb') as f:\n        train_loader = pickle.load(f)\n\n    with open(os.path.join(model_filepath, 'val_loader.pkl'), 'rb') as f:\n        val_loader = pickle.load(f)\n\n    with open(os.path.join(model_filepath, 'test_loader.pkl'), 'rb') as f:\n        test_loader = pickle.load(f)\n\n    train(model, optimizer, torch.nn.CrossEntropyLoss(), train_loader, val_loader, epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T07:41:13.031345Z","iopub.execute_input":"2024-05-21T07:41:13.032041Z","iopub.status.idle":"2024-05-21T07:41:13.042753Z","shell.execute_reply.started":"2024-05-21T07:41:13.032003Z","shell.execute_reply":"2024-05-21T07:41:13.041401Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"raw","source":"# correct = 0\n# total = 0\n# with torch.no_grad():\n#     for data in val_loader:\n#         images, labels = data[0].to(device), data[1].to(device)\n#         predictions = torch.argmax(model(images),dim=1)\n\n#         total += labels.size(0)\n#         correct += (predictions == labels).sum().item()\n\n# print('accuracy = {:f}'.format(correct / total))\n# print('correct: {:d}  total: {:d}'.format(correct, total))","metadata":{"_uuid":"ce6b85c5-91c9-488b-9ae0-74bd3514487f","_cell_guid":"93e16d46-9dc5-41c7-8837-52d4920e6149","id":"MLPxPQrile1o","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-21T07:41:13.044527Z","iopub.execute_input":"2024-05-21T07:41:13.045158Z","iopub.status.idle":"2024-05-21T07:41:13.054176Z","shell.execute_reply.started":"2024-05-21T07:41:13.045063Z","shell.execute_reply":"2024-05-21T07:41:13.052798Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}