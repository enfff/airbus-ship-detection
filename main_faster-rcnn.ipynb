{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9988,"databundleVersionId":868324,"sourceType":"competition"},{"sourceId":8438193,"sourceType":"datasetVersion","datasetId":5026303},{"sourceId":8516397,"sourceType":"datasetVersion","datasetId":5084559,"isSourceIdPinned":true}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# MAIN CONFIGURATIONS\ncreate_log_file = True\nsave_to_drive = False\nmodel_id = '0'  # We will train multiple models with the same settings. Keep it as a string!\nnum_epochs = 40  # Number of epochs the model will train for\nbatch_size = 32\n# init_lr = 0.1 # Initial Learning Rate\ndata_augmentation_type = 'noaug'    # Which data augmentation tecnique are we using?\n                                    # 'noaug':     no data augmentation\n\n# !tree # Prints folder structure\ntest_only = True # When True it doesn't train the model, but it just tests an existing one\ntrain_again = False # Trains the model again for num_epoch times\n\nmodel_filepath = f\"model_{data_augmentation_type}_id{model_id}\"\nmodel_filepath = os.path.join(\"models\", model_filepath)\nprint(f\"{model_filepath = }\")\n\nos.makedirs(model_filepath, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:39:36.992333Z","iopub.execute_input":"2024-06-02T14:39:36.992783Z","iopub.status.idle":"2024-06-02T14:39:37.001163Z","shell.execute_reply.started":"2024-06-02T14:39:36.992742Z","shell.execute_reply":"2024-06-02T14:39:37.000189Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"model_filepath = 'models/model_noaug_id0'\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean everything\n# !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:39:37.003147Z","iopub.execute_input":"2024-06-02T14:39:37.003459Z","iopub.status.idle":"2024-06-02T14:39:37.011748Z","shell.execute_reply.started":"2024-06-02T14:39:37.003435Z","shell.execute_reply":"2024-06-02T14:39:37.010932Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.models as models\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport glob\nimport pandas as pd\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import rotate\nimport numpy as np\n\n# !pip install torchsummary\n# from torchsummary import summary\n!pip install torchmetrics\n!pip install pycocotools faster-coco-eval\n!pip install torchmetrics[detection]","metadata":{"_uuid":"3a8323c1-3053-4c12-9ade-4fb84ebf9533","_cell_guid":"f18fd6df-1d38-488c-8322-fe053a7d6424","id":"kA71_KIbk72N","outputId":"4c825fdc-4725-4bc9-9f3f-c7f07e6431dd","execution":{"iopub.status.busy":"2024-06-02T14:39:37.012822Z","iopub.execute_input":"2024-06-02T14:39:37.013121Z","iopub.status.idle":"2024-06-02T14:40:20.818854Z","shell.execute_reply.started":"2024-06-02T14:39:37.013099Z","shell.execute_reply":"2024-06-02T14:40:20.817600Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.1.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nCollecting pycocotools\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting faster-coco-eval\n  Downloading faster_coco_eval-1.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from faster-coco-eval) (5.18.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from faster-coco-eval) (2.1.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from faster-coco-eval) (9.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->faster-coco-eval) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->faster-coco-eval) (2023.4)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->faster-coco-eval) (8.2.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faster_coco_eval-1.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (596 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools, faster-coco-eval\nSuccessfully installed faster-coco-eval-1.5.4 pycocotools-2.0.7\nRequirement already satisfied: torchmetrics[detection] in /opt/conda/lib/python3.10/site-packages (1.3.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (2.1.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (0.11.2)\nRequirement already satisfied: pycocotools>2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (2.0.7)\nRequirement already satisfied: torchvision>=0.8 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[detection]) (0.16.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics[detection]) (69.0.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics[detection]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics[detection]) (3.1.1)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools>2.0.0->torchmetrics[detection]) (3.7.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics[detection]) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8->torchmetrics[detection]) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8->torchmetrics[detection]) (9.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics[detection]) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8->torchmetrics[detection]) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics[detection]) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(f\"{device = }\")","metadata":{"_uuid":"3a8323c1-3053-4c12-9ade-4fb84ebf9533","_cell_guid":"f18fd6df-1d38-488c-8322-fe053a7d6424","id":"kA71_KIbk72N","outputId":"4c825fdc-4725-4bc9-9f3f-c7f07e6431dd","execution":{"iopub.status.busy":"2024-06-02T14:40:20.820341Z","iopub.execute_input":"2024-06-02T14:40:20.821041Z","iopub.status.idle":"2024-06-02T14:40:20.848172Z","shell.execute_reply.started":"2024-06-02T14:40:20.821012Z","shell.execute_reply":"2024-06-02T14:40:20.847231Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"device = device(type='cuda')\n","output_type":"stream"}]},{"cell_type":"code","source":"import logging\nfrom datetime import datetime\n\nif create_log_file:\n    log_filepath = \"\"\n    logger = logging.getLogger('RootLogger')\n    log_filepath = os.path.join(model_filepath, f\"log\" + \".txt\")\n    print(f\"{log_filepath = }\")\n    \n    logging.basicConfig(filename=log_filepath,\n                        filemode='a',\n                        format='%(asctime)s %(levelname)s %(message)s',\n                        level=logging.DEBUG,\n                        datefmt='%m-%d %H:%M:%S',\n                        force=True)\nelse:\n    logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n                        level=logging.DEBUG,\n                        datefmt='%m-%d %H:%M:%S',\n                        force=True)\n\nif log_filepath:\n    print(log_filepath)\nelse:\n    print(\"No logging\")","metadata":{"_uuid":"e83dab63-8809-4b35-b264-4f1469682d4e","_cell_guid":"cefe5666-0a12-42de-90e4-9e6bfeeab010","id":"03slXsApk-6S","outputId":"30d3206d-bb54-495f-9e71-22ea77ee8cd0","execution":{"iopub.status.busy":"2024-06-02T14:40:20.851648Z","iopub.execute_input":"2024-06-02T14:40:20.852542Z","iopub.status.idle":"2024-06-02T14:40:20.865212Z","shell.execute_reply.started":"2024-06-02T14:40:20.852513Z","shell.execute_reply":"2024-06-02T14:40:20.864192Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"log_filepath = 'models/model_noaug_id0/log.txt'\nmodels/model_noaug_id0/log.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"# TRANSFORMATIONS\n\nfrom torchvision.transforms import v2\n\nimg_dimensions = 224\n\nimg_train_transforms = v2.Compose([\n     v2.RandomRotation(50),\n     v2.RandomAffine(degrees = 0, translate = (0.2, 0.2)),\n     v2.RandomHorizontalFlip(p=0.5),\n    v2.Resize((img_dimensions, img_dimensions)),\n     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]), # alternative to ToTensor\n     #v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\n\nimg_validation_transforms = v2.Compose([\n    v2.Resize((img_dimensions, img_dimensions)),\n     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]), # alternative to ToTensor\n     #v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\n\nimg_test_transforms = v2.Compose([\n    v2.Resize((img_dimensions, img_dimensions)),\n     v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]), # alternative to ToTensor\n     #v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\n\nprint('ok')","metadata":{"_uuid":"86622d71-08ab-4f4a-8f6b-d8d20a66ee67","_cell_guid":"02a5ff4a-6f79-47fc-8863-6c66282ac3cf","id":"LIgECtVqMlCI","execution":{"iopub.status.busy":"2024-06-02T14:40:20.866524Z","iopub.execute_input":"2024-06-02T14:40:20.866863Z","iopub.status.idle":"2024-06-02T14:40:20.913191Z","shell.execute_reply.started":"2024-06-02T14:40:20.866833Z","shell.execute_reply":"2024-06-02T14:40:20.912226Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport torchvision.transforms.functional as F\n\ndef rl_decode(rl_str, height, length):\n  mask = np.zeros(shape=(1,height,length))\n  couples = rl_str.split()\n  for i in range(0, len(couples)-1, 2):\n    # print(i)\n    el = int(couples[i])\n    qty = int(couples[i+1])\n    r,c = np.unravel_index(el,(height,length))\n    for j in range(qty):\n      mask[0, c+j-1, r-1] = 1\n\n    # print(torch.Tensor(mask))\n  return torch.Tensor(mask).reshape((768, 768)).gt(0)\n\ndef show(imgs, rotation=None):\n\n    if rotation:\n          imgs = rotate(imgs, rotation)\n\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n    for i, img in enumerate(imgs):\n        img = img.detach()\n        img = F.to_pil_image(img)\n        axs[0, i].imshow(np.asarray(img))\n        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n\nclass ShipsDataset(torch.utils.data.Dataset):\n    def __init__(self, file_list, targets, transforms = None, target_transforms = None):\n        self.file_list = file_list\n        self.targets = targets\n        self.transform = transforms\n\n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n\n    def __getitem__(self, idx):\n        image = read_image(self.file_list[idx])    # numpy tensor\n\n        image = F.convert_image_dtype(image)\n        # Added this line to fix this problem (ENF) during training\n        # TypeError: Expected input images to be of floating type (in range [0, 1]), but found type torch.uint8 instead\n\n        try:\n            label = self.targets[idx]       # dictionary {\"boxes\": , \"label\": }\n            label['boxes'] = torch.Tensor(label['boxes'])\n            label['labels'] = torch.Tensor(label['labels']).to(dtype=torch.int64).reshape((-1,))\n        except IndexError as e:\n            Warning(f'Errore con {idx = }')\n            plt.imshow(image.permute(1, 2, 0))\n            plt.show()\n\n        if self.transform:\n            image = self.transform(image, label)\n\n        return image, label\n\nprint('ok')","metadata":{"_uuid":"9d46e794-e37a-4cc3-afc4-4c31a63768a3","_cell_guid":"d7c3fba5-7966-4876-a902-31971e6e4121","id":"V1Q6ogjksMqE","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-06-02T14:40:20.914638Z","iopub.execute_input":"2024-06-02T14:40:20.914996Z","iopub.status.idle":"2024-06-02T14:40:20.931208Z","shell.execute_reply.started":"2024-06-02T14:40:20.914966Z","shell.execute_reply":"2024-06-02T14:40:20.930336Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\nfrom torchvision import tv_tensors\n\n# DATASET_DIR = os.path.join(\".\")\nTRAIN_DIR = \"/kaggle/input/airbus-ship-detection/train_v2\"\nTEST_DIR = \"/kaggle/input/airbus-ship-detection/test_v2\"\n# print(DATASET_DIR, TRAIN_DIR, TEST_DIR)\n\ntrain_list = glob.glob(os.path.join(TRAIN_DIR,'*.jpg'))\ntrain_list, test_list = train_test_split(train_list, test_size = 0.97)\ntrain_list, val_list = train_test_split(train_list, test_size = 0.2)\ntest_list, _ = train_test_split(test_list, test_size = 0.99)\ntest_list, _ = train_test_split(test_list, test_size = 0.5)\n\ntrain_data = ShipsDataset(train_list, transforms = img_train_transforms, targets=np.load('/kaggle/input/rcnn-dataset-py/rcnn_targets.npy', allow_pickle='TRUE'))\ntest_data = ShipsDataset(test_list, transforms = img_test_transforms, targets=np.load('/kaggle/input/rcnn-dataset-py/rcnn_targets.npy', allow_pickle='TRUE'))\nval_data = ShipsDataset(val_list, transforms = img_validation_transforms,targets=np.load('/kaggle/input/rcnn-dataset-py/rcnn_targets.npy', allow_pickle='TRUE') )\n\ndef custom_collate_fn(batch):\n    # Why custom_collate_fn? Previously, collate_fn when creating a loader was `lambda x: x`\n    # Pickle doesn't pickle function objects. It expects to find the function object by importing its module and looking up its name.\n    # Lambdas are anonymous functions (no name) so that doesn't work. The solution is to name the function at module level.\n    \n    return batch\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True, collate_fn=custom_collate_fn)\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle = True, collate_fn=custom_collate_fn)\ntest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True, collate_fn=custom_collate_fn)\n\n# Why custom_collate_fn?\n# pickle doesn't pickle function objects. It expects to find the function object by importing its module and looking up its name.\n# Lambdas are anonymous functions (no name) so that doesn't work. The solution is to name the function at module level.\n\nprint(len(train_data),len(train_loader))\nprint(len(val_data), len(val_loader))\nprint(len(test_loader))\n\n# https://pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html#torchvision.models.detection.fasterrcnn_resnet50_fpn\n# La documentazione non è chiara sulla posizione dei punti per le ground-truth!\n# /Users/ludovicamazzucco/Library/Python/3.9/lib/python/site-packages/torchvision/models/detection/generalized_rcnn.py\"","metadata":{"_uuid":"e881bc76-8dce-441c-8229-3a46d9083e40","_cell_guid":"734a631c-9fb5-451d-844c-a7ab77f6b9ff","id":"YW9039lzlK5S","execution":{"iopub.status.busy":"2024-06-02T14:43:10.078014Z","iopub.execute_input":"2024-06-02T14:43:10.078660Z","iopub.status.idle":"2024-06-02T14:45:02.401381Z","shell.execute_reply.started":"2024-06-02T14:43:10.078630Z","shell.execute_reply":"2024-06-02T14:45:02.400398Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"4620 145\n1156 37\n30\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save loaders\ntorch.save(train_loader, os.path.join(model_filepath, 'train_loader.pt'))\ntorch.save(val_loader, os.path.join(model_filepath, 'val_loader.pt'))\ntorch.save(test_loader, os.path.join(model_filepath, 'test_loader.pt'))\n\nprint('Dataset Loaders saved succesfully!')","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:45:02.403606Z","iopub.execute_input":"2024-06-02T14:45:02.404307Z","iopub.status.idle":"2024-06-02T14:46:13.408033Z","shell.execute_reply.started":"2024-06-02T14:45:02.404272Z","shell.execute_reply":"2024-06-02T14:46:13.406990Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Dataset Loaders saved succesfully!\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef get_mean_std(loader):\n    # Compute the mean and standard deviation of all pixels in the dataset  \n    print(\"computing mean and std of this dataset split...\")\n    nimages = 0\n    mean = 0.\n    var = 0.\n    for i, batch in enumerate(loader):\n        inputs = []\n        for el in batch:      \n            inputs.append(el[0][0])\n        batch = torch.stack(inputs, dim=0)\n        # Rearrange batch to be the shape of [B, C, W * H]\n        batch = batch.view(batch.size(0), batch.size(1), -1)\n        # Update total number of images\n        nimages += batch.size(0)\n        # Compute mean and var\n        mean += batch.mean(2).sum(0) \n        var += batch.var(2).sum(0)\n        \n    mean /= nimages\n    var /= nimages\n    std = torch.sqrt(var)\n    print(\"Done\")\n    \n    return mean, std\n\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:46:13.409133Z","iopub.execute_input":"2024-06-02T14:46:13.409414Z","iopub.status.idle":"2024-06-02T14:46:13.417590Z","shell.execute_reply.started":"2024-06-02T14:46:13.409391Z","shell.execute_reply":"2024-06-02T14:46:13.416775Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# M: tensor([0.1927, 0.2736, 0.3115]) A: tensor([0.0893, 0.0827, 0.0817]) original size\n# M: tensor([0.1927, 0.2736, 0.3115]) A: tensor([0.0879, 0.0811, 0.0800]) 224x224\n\n# image_mean_train, image_std_train = get_mean_std(train_loader)\n# image_mean_val, image_std_val = get_mean_std(val_loader)\n\nimage_mean_train = torch.Tensor([0.1543, 0.2125, 0.2388])\nimage_std_train = torch.Tensor([0.1429, 0.1588, 0.1657])\n\nimage_mean_val = torch.Tensor([0.1541, 0.2128, 0.2395])\nimage_std_val = torch.Tensor([0.1415, 0.1594, 0.1676])\n\nimage_mean_test, image_std_test = get_mean_std(test_loader)\n\nprint(f\"{image_mean_train = }, {image_std_train =}\")\nprint(f\"{image_mean_val = }, {image_std_val =}\")\nprint(f\"{image_mean_test = }, {image_std_test =}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:46:13.418836Z","iopub.execute_input":"2024-06-02T14:46:13.419612Z","iopub.status.idle":"2024-06-02T14:46:29.590345Z","shell.execute_reply.started":"2024-06-02T14:46:13.419562Z","shell.execute_reply":"2024-06-02T14:46:29.589357Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"computing mean and std of this dataset split...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Done\nimage_mean_train = tensor([0.1543, 0.2125, 0.2388]), image_std_train =tensor([0.1429, 0.1588, 0.1657])\nimage_mean_val = tensor([0.1541, 0.2128, 0.2395]), image_std_val =tensor([0.1415, 0.1594, 0.1676])\nimage_mean_test = tensor([0.2094, 0.2899, 0.3235]), image_std_test =tensor([0.0836, 0.0766, 0.0753])\n","output_type":"stream"}]},{"cell_type":"code","source":"## STEP 1. freeze backbone layers, add final layers and train the network\n\nmodel_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n\nfor name, param in model_rcnn.named_parameters():\n      param.requires_grad = False\n\nnum_classes = 2 # background, ship\nin_features = model_rcnn.roi_heads.box_predictor.cls_score.in_features\nmodel_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nprint('ok')","metadata":{"_uuid":"d03e9038-bb70-4a25-844c-caf367db09b3","_cell_guid":"205f69cf-8dd0-443e-a21a-345bb8c0a3ac","id":"5J9M_bnAxnDk","execution":{"iopub.status.busy":"2024-06-02T14:46:29.592687Z","iopub.execute_input":"2024-06-02T14:46:29.592995Z","iopub.status.idle":"2024-06-02T14:46:31.412098Z","shell.execute_reply.started":"2024-06-02T14:46:29.592955Z","shell.execute_reply":"2024-06-02T14:46:31.411129Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:01<00:00, 163MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"def save_checkpoint(epoch, model, optimizer, scheduler, train_loss, lrs, model_name=\"model.tar\"):\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'train_loss': train_loss,\n        'lrs': lrs\n    }, os.path.join(model_filepath, model_name))\n    print(\"Saved model\")\n\nprint(\"ok\")","metadata":{"_uuid":"6eba70ff-96e9-4522-b787-d1946d2b9017","_cell_guid":"528b2af3-593a-4e0a-ae5b-ef64c8d760e4","id":"Du5q6_RRCmD4","execution":{"iopub.status.busy":"2024-06-02T14:46:31.413151Z","iopub.execute_input":"2024-06-02T14:46:31.413424Z","iopub.status.idle":"2024-06-02T14:46:31.419899Z","shell.execute_reply.started":"2024-06-02T14:46:31.413401Z","shell.execute_reply":"2024-06-02T14:46:31.418926Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"# TRAIN\n# import gc\nfrom torchvision.models.detection.transform import GeneralizedRCNNTransform\n\nlrs = [] # list containing lrs\n\ndef train(model, optimizer, scheduler, loss_fn, train_loader, val_loader, training_loss=0, epochs=1, device=\"cpu\", start_from_epoch=0):\n    \n    model.transform.image_mean = image_mean_train\n    model.transform.image_std = image_std_train\n    model._skip_resize = True\n    \n    for epoch in range(start_from_epoch, epochs): # if start_from_epoch=5, epoch will be [5, 6, 7, ..., epochs-1]\n        \n        lrs.append(scheduler.get_last_lr())\n        training_loss = 0.0\n        batch_cumsum = 0\n        model.train()\n\n        for i, batch in enumerate(train_loader):\n            logger.info(f\"E: {str(epoch)} B: {str(i)}\")\n            print(f\"epoch {epoch} batch {i}\")\n            batch_cumsum += len(batch) # needed to compute the training loss later\n            optimizer.zero_grad()\n            \n            # filtering out empty images (model does not accept empty targets)\n            inputs = []\n            targets = []\n            for el in batch:       # el = ((image,dict),dict) when transforms are active\n                if el[1]['boxes'].size()[0] != 0:\n                    inputs.append(el[0][0].to(device))\n                    targets.append({\"boxes\": el[0][1][\"boxes\"].to(device),\"labels\": el[0][1][\"labels\"].to(device)})\n                    \n                    # print(f\"{el = }\")\n                    # Example el\n                    # el = (tensor([[[0.1006, 0.1249, 0.1552,  ..., 0.1552, 0.1395, 0.1321],\n                    #          [0.1224, 0.1331, 0.1243,  ..., 0.1218, 0.1260, 0.1410],\n                    #          [0.0948, 0.1149, 0.1300,  ..., 0.1381, 0.1356, 0.1356],\n                    #          ...,\n                    #          [0.1789, 0.1738, 0.1818,  ..., 0.1401, 0.1428, 0.1169],\n                    #          [0.1591, 0.1532, 0.1752,  ..., 0.1555, 0.1481, 0.1131],\n                    #          [0.1664, 0.1698, 0.1564,  ..., 0.1268, 0.1538, 0.1393]],\n\n                    #         [[0.2291, 0.2504, 0.2689,  ..., 0.2807, 0.2650, 0.2576],\n                    #          [0.2510, 0.2586, 0.2380,  ..., 0.2473, 0.2515, 0.2664],\n                    #          [0.2234, 0.2404, 0.2437,  ..., 0.2636, 0.2611, 0.2611],\n                    #          ...,\n                    #          [0.2966, 0.2914, 0.2995,  ..., 0.2460, 0.2486, 0.2228],\n                    #          [0.2768, 0.2709, 0.2928,  ..., 0.2613, 0.2540, 0.2190],\n                    #          [0.2840, 0.2874, 0.2741,  ..., 0.2327, 0.2596, 0.2452]],\n\n                    #         [[0.2880, 0.3092, 0.3317,  ..., 0.3396, 0.3238, 0.3164],\n                    #          [0.3098, 0.3174, 0.3007,  ..., 0.3062, 0.3103, 0.3253],\n                    #          [0.2822, 0.2993, 0.3064,  ..., 0.3224, 0.3199, 0.3199],\n                    #          ...,\n                    #          [0.3358, 0.3306, 0.3387,  ..., 0.2813, 0.2918, 0.2659],\n                    #          [0.3160, 0.3101, 0.3320,  ..., 0.2966, 0.2971, 0.2622],\n                    #          [0.3232, 0.3266, 0.3133,  ..., 0.2680, 0.3028, 0.2883]]]), {'boxes': tensor([[0.3932, 0.8464, 0.5208, 0.8776],\n                    #         [0.2331, 0.2643, 0.3268, 0.3060],\n                    #         [0.2435, 0.2995, 0.4062, 0.3724],\n                    #         [0.7188, 0.6198, 0.8281, 0.6784],\n                    #         [0.2279, 0.3229, 0.4154, 0.4128]]), 'labels': tensor([1, 1, 1, 1, 1])})\n                    \n            if len(inputs) == 0:\n                continue\n         \n            output = model(inputs,targets)  # NOTE: output is a dict with already computed losses within!\n\n            \"\"\" EXAMPLE :\n            {'loss_classifier': tensor(1.0206, grad_fn=<NllLossBackward0>),\n             'loss_box_reg': tensor(0.0071, grad_fn=<DivBackward0>),\n             'loss_objectness': tensor(1.8541), 'loss_rpn_box_reg': tensor(1.8591)}\n             \n             How losses are computed:\n             \n             -loss_classifier-\n             classification_loss = F.cross_entropy(class_logits, labels)\n             \n             -loss_box_reg-\n             box_loss = F.smooth_l1_loss(\n                box_regression[sampled_pos_inds_subset, labels_pos],\n                regression_targets[sampled_pos_inds_subset],\n                beta=1 / 9,\n                reduction=\"sum\",\n            )\n            box_loss = box_loss / labels.numel()\n            \n            -loss_rpn_box_reg-\n            box_loss = F.smooth_l1_loss(\n            pred_bbox_deltas[sampled_pos_inds],\n            regression_targets[sampled_pos_inds],\n            beta=1 / 9,\n            reduction=\"sum\",\n            ) / (sampled_inds.numel())\n            \n            -loss_objectness-\n            objectness_loss = F.binary_cross_entropy_with_logits(objectness[sampled_inds], labels[sampled_inds])\n             \n             \"\"\"\n          \n            loss = sum(loss for loss in output.values())\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.data.item() * len(batch)\n            \n#             del inputs\n#             del targets\n#             gc.collect()    \n        \n        scheduler.step() # changes LR\n        training_loss /= batch_cumsum\n        save_checkpoint(epoch, model, optimizer, scheduler, training_loss, lrs)\n        \n        # VALIDATION\n        model.transform.image_mean = image_mean_val\n        model.transform.image_std = image_std_val\n        \n        model.train()\n        num_correct = 0\n        num_examples = 0\n        valid_loss = 0\n        \n        with torch.no_grad():\n            for i,batch in enumerate(val_loader):\n                print(\"batch\", i)\n                inputs = []\n                targets = []\n\n                for el in batch:       # el = (image,labels)\n                    if el[1]['boxes'].size()[0] != 0:\n                        inputs.append(el[0][0].to(device))\n                        targets.append({\"boxes\": el[0][1][\"boxes\"].to(device),\"labels\": el[0][1][\"labels\"].to(device)})\n\n                if len(inputs) == 0:\n                    continue\n                \n                output = model(inputs, targets)\n\n                loss = sum(loss for loss in output.values())\n                valid_loss += loss.data.item() *len(batch)\n\n#                 del inputs\n#                 del targets\n#                 gc.collect()\n\n        valid_loss /= len(val_loader.dataset)\n        \n        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, lr: {:.4f}'.format(epoch, training_loss,\n        valid_loss, optimizer.param_groups[0][\"lr\"]))\n\n        logger.info('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, lr: {:.4f}'.format(epoch, training_loss,\n        valid_loss, optimizer.param_groups[0][\"lr\"]))\n        \n\n# from torchvision.utils import draw_bounding_boxes\n# score_threshold = .5\nprint('ok')","metadata":{"_uuid":"a9a507f8-c784-4847-a373-79f1a84ba9aa","_cell_guid":"ee5ce9ae-8a53-4e0e-9db9-99e5a583fd43","id":"Mv8b06EulUK2","execution":{"iopub.status.busy":"2024-06-02T14:46:31.421347Z","iopub.execute_input":"2024-06-02T14:46:31.421676Z","iopub.status.idle":"2024-06-02T14:46:31.445842Z","shell.execute_reply.started":"2024-06-02T14:46:31.421646Z","shell.execute_reply":"2024-06-02T14:46:31.444994Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"{device = }\")\nmodel = model_rcnn.to(device)\ntorch.compile(model)\noptimizer = optim.Adam(params = model.parameters(), lr = 1e-4, weight_decay=0.01)\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(\n    optimizer,\n    lr_lambda = lambda epoch: 0.8 ** epoch,\n)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"_uuid":"5a384475-40a4-4c13-9c8a-8efeb96ed8f2","_cell_guid":"2f312861-b958-45c9-92e5-ed33d593194f","id":"2LUibV2Elccf","execution":{"iopub.status.busy":"2024-06-02T14:46:31.447014Z","iopub.execute_input":"2024-06-02T14:46:31.447388Z","iopub.status.idle":"2024-06-02T14:46:32.345601Z","shell.execute_reply.started":"2024-06-02T14:46:31.447358Z","shell.execute_reply":"2024-06-02T14:46:32.344406Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"device = device(type='cuda')\n","output_type":"stream"}]},{"cell_type":"code","source":"# START MODEL TRAINING\n\nif not test_only:\n    logger.info(f\"Beginning training, {num_epochs = }, {device = }\")\n    print(f\"Beginning training, {num_epochs = }\")\n    \n    train(model, optimizer, scheduler, criterion, train_loader, val_loader, epochs=num_epochs, device=device)\n    torch.save(model.state_dict(), 'model_state_dict')\n    \n    fig, ax = plt.subplots()\n    ax.plot(lrs)    \n    ax.set(xlabel='epoch', ylabel='learning rate value')\n    fig.savefig(os.path.join(model_filepath, \"lrs.png\"))\n    print(f\"{lrs = }\")\n    logger.info(f\"{lrs = }\")","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:46:32.347611Z","iopub.execute_input":"2024-06-02T14:46:32.348016Z","iopub.status.idle":"2024-06-02T14:46:32.355258Z","shell.execute_reply.started":"2024-06-02T14:46:32.347983Z","shell.execute_reply":"2024-06-02T14:46:32.354302Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Per scaricare il contenuto di kaggle/working (e quindi recuperare i modelli)\n# Crea lo zip della cartella che è stata creata contenente il modello e i log\n\nfrom IPython.display import FileLink\n!zip -r file.zip {model_filepath}\nFileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:46:32.356706Z","iopub.execute_input":"2024-06-02T14:46:32.357320Z","iopub.status.idle":"2024-06-02T14:46:42.488851Z","shell.execute_reply.started":"2024-06-02T14:46:32.357296Z","shell.execute_reply":"2024-06-02T14:46:42.487860Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"  adding: models/model_noaug_id0/ (stored 0%)\n  adding: models/model_noaug_id0/log.txt (stored 0%)\n  adding: models/model_noaug_id0/test_loader.pt (deflated 86%)\n  adding: models/model_noaug_id0/train_loader.pt (deflated 86%)\n  adding: models/model_noaug_id0/val_loader.pt (deflated 86%)\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"\nfrom torchmetrics.detection import MeanAveragePrecision\nimport torchvision.transforms.functional as F\n\ndef test(model, test_loader, device=\"cpu\"): \n    \n    model.transform.image_mean = image_mean_test\n    model.transform.image_std = image_std_test\n    model._skip_resize = True\n    \n    model.eval()\n    num_correct = 0\n    num_examples = 0\n    test_loss = 0\n    metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds=[0.75])\n    mAP = 0\n    \n    for i,batch in enumerate(test_loader):\n        print(\"batch\", i)\n        \n        inputs = []\n        targets = []\n        \n        for el in batch:       # el = ((image,dict),dict)\n            if el[1]['boxes'].size()[0] != 0:\n                inputs.append(el[0][0].to(device))\n                targets.append(el[0][1])\n                \n        if len(inputs) == 0:\n            continue\n        \n        output = model(inputs)\n        # print(type(model(torch.cuda.FloatTensor(inputs))))\n        print(\"out :\\n\", output)\n        print(\"target :\\n\",targets)\n        #     # Example output\n        #     {'boxes': tensor([[\n        #       0.3801,  0.3060,  3.5638,  3.0348],\n        #     [ 0.2037,  0.6570,  1.9538,  4.9389],\n        #     [ 0.4993,  0.7045,  5.1531,  5.5368],\n        #     [ 0.7172,  0.0860,  8.0819,  3.2724],\n        #     [ 0.3548,  1.4842,  3.9183,  9.8673],\n        #     [ 0.9226,  0.4096, 11.7943,  6.0310]], grad_fn=<StackBackward0>),\n        #     labels': tensor([1, 1, 1, 1, 1, 1]), 'scores': tensor([0.9762, 0.9498, 0.9188, 0.8941, 0.3722, 0.2909],\n        #     grad_fn=<IndexBackward0>)},\n        \n        \"\"\"\n        scores come from RoIHeads class:\n        pred_scores = F.softmax(class_logits, -1)\n        after deleting empy boxes, low scored boxes and applying non-max suppression\n        \"\"\"\n        for dic in output:\n            dic[\"boxes\"] = dic[\"boxes\"].to(torch.device(\"cpu\"))\n            dic[\"labels\"] = dic[\"labels\"].to(torch.device(\"cpu\"))\n            dic[\"scores\"] = dic[\"scores\"].to(torch.device(\"cpu\"))\n            \n        res = metric(output,targets)\n        mAP += res['map_75']\n        #print(res)\n\n        \n    mAP /= len(test_loader)  \n    print( 'Mean Average Precision: {:.4f}'.format(mAP))\n\nprint(\"ok\")","metadata":{"execution":{"iopub.status.busy":"2024-06-02T15:04:10.981825Z","iopub.execute_input":"2024-06-02T15:04:10.982529Z","iopub.status.idle":"2024-06-02T15:04:10.994962Z","shell.execute_reply.started":"2024-06-02T15:04:10.982497Z","shell.execute_reply":"2024-06-02T15:04:10.993683Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# START MODEL TEST\n# DA SISTEMARE\n# TODO\n\ndo_model_test = False\n\nif do_model_test:\n    checkpoint = torch.load(os.path.join('/kaggle/input/model-trained', \"model.tar\")) # LUDO\n    #checkpoint = torch.load(os.path.join(model_filepath, \"model.tar\")) # ENF\n    # model.load_state_dict(checkpoint['model_state_dict'])\n\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        print(\"model is now using cuda\")\n\n    test(model.to(device), test_loader)\n\ncheckpoint = torch.load(os.path.join('/kaggle/input/model-trained', \"model.tar\")) # ludo\n#checkpoint = torch.load(os.path.join(model_filepath, \"model.tar\")) # enf\nmodel.load_state_dict(checkpoint['model_state_dict'])\ntest(model.to(device), test_loader, device=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T15:04:13.708018Z","iopub.execute_input":"2024-06-02T15:04:13.708377Z","iopub.status.idle":"2024-06-02T15:04:29.651866Z","shell.execute_reply.started":"2024-06-02T15:04:13.708349Z","shell.execute_reply":"2024-06-02T15:04:29.650812Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"batch 0\nout :\n [{'boxes': tensor([[0.0000, 0.9076, 3.6473, 9.2585]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0688], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2154, 1.3744, 2.2181]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.2810], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[ 0.0000,  0.4372,  1.4807,  3.4329],\n        [ 0.0000, 92.3855,  1.5276, 98.1371]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4067, 0.1025], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0793, 1.2802, 2.1178],\n        [0.0000, 0.0527, 0.5833, 1.9905],\n        [0.0000, 0.1533, 2.1731, 1.6854]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.1595, 0.0886, 0.0686], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0423, 0.4873, 1.7388],\n        [0.0000, 0.0365, 0.9545, 1.2838]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4457, 0.2940], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.8525e-01, 1.3319e+00, 2.5310e+00],\n        [2.2103e+02, 2.0030e-01, 2.2357e+02, 4.1469e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.2607, 0.0714], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.8398, 0.0846, 0.9987, 0.2539],\n        [0.7005, 0.7148, 0.7904, 0.8099],\n        [0.3503, 0.0794, 0.4245, 0.1484],\n        [0.4089, 0.9271, 0.4987, 1.0000]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.7031, 0.7396, 0.7135, 0.7487]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1497, 0.1823, 0.1602, 0.1979],\n        [0.2057, 0.0000, 0.2148, 0.0143],\n        [0.0247, 0.3164, 0.0456, 0.3398],\n        [0.2760, 0.0716, 0.2917, 0.0911],\n        [0.2799, 0.2956, 0.2995, 0.3138]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.2044, 0.6576, 0.3841, 0.8216]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0924, 0.1654, 0.4609, 0.2669]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0091, 0.2383, 0.4388, 0.3594]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1810, 0.9635, 0.2305, 1.0000],\n        [0.1693, 0.9531, 0.2174, 0.9922],\n        [0.1237, 0.9245, 0.1445, 0.9336],\n        [0.1237, 0.9310, 0.1380, 0.9375],\n        [0.2526, 0.8607, 0.2604, 0.8659],\n        [0.2344, 0.8190, 0.2422, 0.8307],\n        [0.1263, 0.9180, 0.1445, 0.9271],\n        [0.1445, 0.9219, 0.1562, 0.9284],\n        [0.1589, 0.9831, 0.1758, 0.9987]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])}, {'boxes': tensor([[0.7839, 0.8620, 0.8060, 0.8854],\n        [0.1003, 0.4492, 0.1315, 0.4805],\n        [0.0456, 0.3737, 0.1198, 0.4596],\n        [0.8034, 0.8750, 0.8581, 0.9258]]), 'labels': tensor([1, 1, 1, 1])}]\nbatch 1\nout :\n [{'boxes': tensor([[0.0000, 0.0660, 1.4020, 2.2057],\n        [1.1223, 0.2863, 5.1300, 2.3347],\n        [0.0000, 0.0255, 1.0325, 0.9920],\n        [3.0464, 0.2042, 7.3693, 2.1059]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.4323, 0.1663, 0.1457, 0.0766], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1211, 1.2258, 1.7955]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1360], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[221.5071,   3.9228, 223.6974,  11.6656],\n        [  0.0000,   0.7463,   1.7461,   3.3587],\n        [  0.0000,   0.5870,   2.8486,   4.7911]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.0932, 0.0838, 0.0566], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.4727, 0.4232, 0.5117, 0.4661]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9089, 0.4375, 0.9232, 0.4505]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4857, 0.8372, 0.7292, 1.0000]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3854, 0.1836, 0.4141, 0.2018]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7891, 0.0872, 0.8659, 0.1823],\n        [0.7630, 0.0951, 0.8229, 0.1641]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.0560, 0.8880, 0.0872, 0.9089]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9987, 0.8802, 1.0000, 0.9206]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5534, 0.2878, 0.5690, 0.2969]]), 'labels': tensor([1])}]\nbatch 2\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.9848e-01, 1.3532e+00, 4.0412e+00],\n        [0.0000e+00, 1.5615e-03, 1.0065e+00, 2.0911e+00],\n        [0.0000e+00, 4.3300e-01, 3.1415e+00, 4.8457e+00],\n        [2.2204e+02, 1.3816e-01, 2.2381e+02, 1.6794e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.3333, 0.1870, 0.0780, 0.0770], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.1745, 0.8164, 0.2643, 0.8620]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0599, 0.6406, 0.1432, 0.6992]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4492, 0.0495, 0.5273, 0.1003],\n        [0.3008, 0.0625, 0.4466, 0.1615]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7565, 0.5768, 0.7708, 0.5898]]), 'labels': tensor([1])}]\nbatch 3\nout :\n [{'boxes': tensor([[0.0000, 0.0359, 1.4886, 2.4768],\n        [0.0000, 0.0000, 0.7149, 1.9501]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1726, 0.0987], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0228, 0.3084, 1.6510],\n        [0.0000, 0.0229, 0.9397, 1.5556]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.0918, 0.0832], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 0.0000e+00, 1.1714e+00, 1.6315e+00],\n        [1.1565e+00, 1.1465e-01, 4.6956e+00, 1.0450e+00],\n        [0.0000e+00, 5.5367e-02, 2.2823e+00, 6.7299e-01],\n        [0.0000e+00, 1.0575e-01, 9.0069e-01, 3.3553e+00],\n        [1.8946e-03, 1.7100e+00, 2.4751e+00, 1.3658e+01]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.4257, 0.3728, 0.2040, 0.1008, 0.0637], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.6380, 0.0208, 0.8932, 0.2214]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3763, 0.3203, 0.4023, 0.3372],\n        [0.3971, 0.4245, 0.5143, 0.4609],\n        [0.3164, 0.3216, 0.3789, 0.3503]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.9544, 0.7005, 0.9844, 0.7318]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7214, 0.0000, 0.8724, 0.0794]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4844, 0.6029, 0.4987, 0.6120]]), 'labels': tensor([1])}]\nbatch 4\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.7161, 0.7956, 0.9857, 0.8542],\n        [0.6549, 0.8398, 0.9987, 0.9271]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.1146, 0.3359, 0.1901, 0.3958],\n        [0.6042, 0.9180, 0.7318, 1.0000]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.8372, 0.3503, 0.8568, 0.3750]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5560, 0.6693, 0.5742, 0.6862],\n        [0.6862, 0.5846, 0.7122, 0.6107]]), 'labels': tensor([1, 1])}]\nbatch 5\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5911, 0.4479, 0.6354, 0.4727],\n        [0.5885, 0.4388, 0.6302, 0.4622]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.6094, 0.3737, 0.6393, 0.3997],\n        [0.0859, 0.4909, 0.1094, 0.5026],\n        [0.3346, 0.2266, 0.3971, 0.2409],\n        [0.0924, 0.5026, 0.1016, 0.5039],\n        [0.4297, 0.2318, 0.4805, 0.2565]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.8711, 0.0156, 0.8906, 0.0755],\n        [0.4583, 0.3477, 0.5026, 0.3958],\n        [0.3529, 0.1146, 0.3646, 0.1341],\n        [0.3398, 0.0599, 0.3594, 0.0781],\n        [0.9987, 0.5560, 1.0000, 0.6003],\n        [0.3281, 0.0833, 0.3633, 0.1536]]), 'labels': tensor([1, 1, 1, 1, 1, 1])}]\nbatch 6\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.3172, 1.9135],\n        [0.0000, 0.0000, 0.8570, 1.6986]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1993, 0.1927], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1000, 1.2147, 1.9763]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0752], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.0625, 0.8945, 0.0898, 0.9271]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1068, 0.4531, 0.1510, 0.4805],\n        [0.1081, 0.5169, 0.1615, 0.5599],\n        [0.9987, 0.5495, 1.0000, 0.5677],\n        [0.1510, 0.5482, 0.1836, 0.5729],\n        [0.1510, 0.4349, 0.1836, 0.4544],\n        [0.1549, 0.4466, 0.1862, 0.4635],\n        [0.0130, 0.3919, 0.0651, 0.4193],\n        [0.1237, 0.5339, 0.1667, 0.5677],\n        [0.1458, 0.5469, 0.1680, 0.5651]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])}, {'boxes': tensor([[0.6354, 0.1576, 0.6471, 0.1706]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2773, 0.6263, 0.2839, 0.6328]]), 'labels': tensor([1])}]\nbatch 7\nout :\n [{'boxes': tensor([[0.0000, 0.1375, 1.1641, 1.6995]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.3011], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5456, 0.4896, 0.6159, 0.5417]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1523, 0.0482, 0.1823, 0.0638]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0924, 0.7786, 0.3073, 0.9622],\n        [0.6185, 0.3281, 0.7227, 0.4180]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.2812, 0.4284, 0.3607, 0.4544]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8763, 0.5130, 0.9297, 0.5430],\n        [0.6341, 0.7266, 0.6992, 0.7656]]), 'labels': tensor([1, 1])}]\nbatch 8\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[1.2610e+02, 1.4362e-01, 1.2946e+02, 1.6209e+00],\n        [2.2023e+02, 1.6242e-01, 2.2335e+02, 1.5248e+00],\n        [0.0000e+00, 1.3309e-01, 1.1839e+00, 1.5887e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.1201, 0.1201, 0.0802], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 1.0912, 1.7602],\n        [0.0000, 0.0000, 0.3502, 1.9572],\n        [0.0000, 0.0000, 0.8862, 3.2856],\n        [0.0000, 0.0785, 2.5606, 2.4698],\n        [0.0000, 0.0222, 1.9594, 0.9924],\n        [0.0000, 0.0000, 0.8169, 0.9476],\n        [0.0000, 0.2755, 2.8674, 4.7029]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.4451, 0.4219, 0.3386, 0.3068, 0.3010, 0.2376, 0.0906],\n       device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1163, 0.9942, 1.4724],\n        [0.0000, 0.2321, 0.6766, 2.7259],\n        [0.0000, 0.1575, 2.2834, 1.0288],\n        [0.0000, 0.2477, 2.8715, 1.7383]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.4742, 0.4580, 0.1507, 0.0810], device='cuda:0',\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.4922, 0.9323, 0.5026, 0.9453],\n        [0.5964, 0.5872, 0.6055, 0.6042]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7057, 0.4857, 0.8151, 0.5352]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5755, 0.1615, 0.6133, 0.1992]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2135, 0.6836, 0.3724, 0.8854],\n        [0.2982, 0.7943, 0.3177, 0.8190],\n        [0.2292, 0.7188, 0.3060, 0.8151],\n        [0.7734, 0.5508, 0.9987, 0.8438]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.4362, 0.0859, 0.4440, 0.0951],\n        [0.5430, 0.2461, 0.5820, 0.2734]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7201, 0.5638, 0.7318, 0.5742],\n        [0.5560, 0.5898, 0.5690, 0.6029]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.5456, 0.4049, 0.5573, 0.4141]]), 'labels': tensor([1])}]\nbatch 9\nout :\n [{'boxes': tensor([[0.0000, 0.0969, 1.1104, 1.6552],\n        [0.0000, 0.1445, 0.8455, 2.9029],\n        [0.0000, 0.0965, 2.0500, 1.1194],\n        [0.0000, 0.0774, 0.6059, 1.5315],\n        [0.0000, 0.1493, 2.7697, 1.7848],\n        [0.0000, 0.0523, 0.9017, 0.9969]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.1876, 0.1239, 0.1228, 0.1196, 0.0869, 0.0790], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[  0.0000,   0.3230,   1.2189,   3.1424],\n        [221.9137,   0.6993, 223.7644,   4.8981]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4533, 0.0751], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 9.3936e-02, 1.5918e+00, 2.7198e+00],\n        [2.2124e+02, 1.4636e-01, 2.2366e+02, 2.3768e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1977, 0.0922], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0522, 1.0333, 2.5932]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.2112], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0693, 1.2496, 2.2082],\n        [0.0000, 1.0257, 2.8126, 8.7188]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.6714, 0.0878], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0350, 1.0307, 1.8294]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1122], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1431, 1.6306, 2.4990],\n        [0.0000, 0.1057, 1.0339, 1.9934]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1211, 0.0825], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.3659, 0.2057, 0.4688, 0.2396],\n        [0.4141, 0.5755, 0.5221, 0.6263],\n        [0.1445, 0.0117, 0.2539, 0.0404]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.7083, 0.8633, 0.7318, 0.8854]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4466, 0.6055, 0.5820, 0.6523]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2591, 0.8633, 0.2865, 0.8763],\n        [0.9076, 0.6172, 0.9141, 0.6432],\n        [0.6875, 0.8047, 0.6992, 0.8125]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.5820, 0.2292, 0.5924, 0.2474],\n        [0.0078, 0.9206, 0.0156, 0.9401]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.5339, 0.9674, 0.5586, 0.9740]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3672, 0.7148, 0.4635, 0.7799],\n        [0.0547, 0.8451, 0.1523, 0.9115]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.6823, 0.9857, 0.6979, 1.0000],\n        [0.6016, 0.8047, 0.6159, 0.8203],\n        [0.5195, 0.7005, 0.5339, 0.7253]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.7161, 0.7122, 0.7604, 0.7266]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6224, 0.7096, 0.6393, 0.7214]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7760, 0.5990, 0.7852, 0.6172],\n        [0.9596, 0.9844, 0.9714, 0.9935]]), 'labels': tensor([1, 1])}]\nbatch 10\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.8541, 0.5569, 5.1001]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0780], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 4.4740e-02, 1.5401e+00, 2.1429e+00],\n        [0.0000e+00, 0.0000e+00, 5.7816e-01, 2.2009e+00],\n        [2.1765e-03, 5.7834e-03, 7.9246e-01, 9.1276e-01]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.7214, 0.4439, 0.3638], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[  0.0000,   0.2415,   1.4822,   3.0539],\n        [220.9870,   0.5660, 223.6379,   3.9445]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4875, 0.0749], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.7474, 0.8164, 0.9987, 0.9531],\n        [0.5846, 0.6315, 0.8776, 0.7891],\n        [0.7734, 0.4753, 0.9922, 0.5872],\n        [0.9987, 0.2943, 1.0000, 0.3372]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.5560, 0.3854, 0.6628, 0.4596]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3516, 0.8971, 0.3685, 0.9128]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7135, 0.0352, 0.9987, 0.1276]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5703, 0.6706, 0.7786, 0.7279]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4466, 0.0742, 0.5039, 0.0964],\n        [0.1979, 0.2344, 0.3060, 0.2852],\n        [0.4323, 0.6732, 0.5130, 0.7031],\n        [0.5599, 0.0221, 0.6497, 0.0599],\n        [0.1862, 0.8151, 0.2773, 0.8333]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.3529, 0.6250, 0.5182, 0.7747],\n        [0.5443, 0.2904, 0.8919, 0.5990],\n        [0.4987, 0.5443, 0.5404, 0.5651],\n        [0.5651, 0.4792, 0.6029, 0.5104]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.0990, 0.5977, 0.1536, 0.6224]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3685, 0.9219, 0.3750, 0.9284]]), 'labels': tensor([1])}]\nbatch 11\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2238, 1.1598, 2.2819]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1780], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 9.6271e-02, 1.4193e+00, 2.4864e+00],\n        [2.1167e+00, 1.4799e-01, 5.9027e+00, 2.1723e+00],\n        [6.8607e-01, 2.5756e-01, 4.7554e+00, 2.7742e+00],\n        [0.0000e+00, 2.0888e-02, 1.0768e+00, 1.1780e+00],\n        [3.4712e-03, 3.5995e+00, 9.5678e-01, 8.8396e+00],\n        [4.9812e-01, 2.9764e+00, 4.5874e+00, 1.0813e+01],\n        [6.1480e-03, 5.2464e+00, 9.3961e-01, 1.0897e+01],\n        [2.2187e+02, 1.9366e-01, 2.2376e+02, 1.9519e+00],\n        [6.8199e-01, 2.3401e+00, 8.4840e+00, 1.1257e+01],\n        [0.0000e+00, 7.0224e-01, 3.0155e+00, 4.8440e+00],\n        [5.3098e-03, 6.2927e+00, 6.3726e-01, 1.2080e+01]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.5941, 0.5909, 0.4677, 0.4512, 0.2930, 0.2657, 0.1005, 0.0648, 0.0548,\n        0.0545, 0.0514], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.3789, 0.5221, 0.4219, 0.5495]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5807, 0.5130, 0.6589, 0.5612],\n        [0.4609, 0.5260, 0.6836, 0.6562],\n        [0.7461, 0.7682, 0.7591, 0.7747]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.3880, 0.4154, 0.5690, 0.5729]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1836, 0.6094, 0.2266, 0.6341]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2786, 0.5964, 0.2969, 0.6146],\n        [0.1784, 0.3086, 0.2148, 0.3398],\n        [0.0742, 0.7279, 0.1276, 0.7656]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.2201, 0.5221, 0.4245, 0.6901]]), 'labels': tensor([1])}]\nbatch 12\nout :\n [{'boxes': tensor([[0.0000, 0.1365, 1.3273, 1.7179]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1481], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1517, 1.1886, 2.4199],\n        [0.0000, 0.1053, 0.5399, 2.0957]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1976, 0.1339], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0386, 1.1004, 1.5668],\n        [0.0000, 0.0248, 0.2966, 1.6790]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.3102, 0.2256], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1967, 1.1646, 1.8632],\n        [0.0000, 0.1655, 1.9822, 1.4389],\n        [0.0000, 3.4680, 0.2909, 7.3467]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.1747, 0.0921, 0.0593], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.9375, 0.5104, 0.9987, 0.5521],\n        [0.9674, 0.5013, 0.9922, 0.5208],\n        [0.2135, 0.2409, 0.2656, 0.2721],\n        [0.9609, 0.5260, 0.9987, 0.5508],\n        [0.2826, 0.6393, 0.3555, 0.6771]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.1576, 0.2604, 0.1719, 0.2734]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0273, 0.7760, 0.0482, 0.7995]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9570, 0.1615, 0.9779, 0.1810]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3646, 0.6523, 0.7057, 0.8333]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5208, 0.0755, 0.5456, 0.1003],\n        [0.1784, 0.2852, 0.1927, 0.3008],\n        [0.2513, 0.7969, 0.2643, 0.8099]]), 'labels': tensor([1, 1, 1])}]\nbatch 13\nout :\n [{'boxes': tensor([[0.0000, 0.0271, 1.0927, 1.6588],\n        [0.0000, 0.0863, 2.5050, 1.8223],\n        [0.0000, 0.0161, 0.3966, 1.7525],\n        [0.0000, 0.0697, 2.0431, 1.0125],\n        [0.0000, 0.0158, 0.9342, 0.9058],\n        [0.0000, 0.0380, 0.8579, 3.0167]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.1504, 0.1153, 0.1102, 0.0772, 0.0738, 0.0703], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1960, 1.1119, 2.0312]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0958], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.2833e-01, 5.1848e-01, 2.7290e+00],\n        [0.0000e+00, 6.6302e+00, 1.1917e+00, 1.2004e+01],\n        [0.0000e+00, 2.1907e-01, 1.6279e+00, 2.3949e+00],\n        [2.2170e+02, 4.6668e-01, 2.2373e+02, 4.3107e+00],\n        [2.1977e+02, 1.5697e-01, 2.2361e+02, 2.8830e+00],\n        [2.2158e+02, 3.1136e+00, 2.2377e+02, 1.3656e+01]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.2735, 0.1880, 0.1392, 0.0958, 0.0792, 0.0542], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 7.3953e-02, 1.1744e+00, 1.8633e+00],\n        [0.0000e+00, 1.2620e-01, 1.6038e+00, 2.6400e+00],\n        [2.2153e+02, 1.1769e-01, 2.2365e+02, 2.2973e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.5862, 0.5203, 0.1891], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.4453, 0.5651, 0.4648, 0.5885]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9987, 0.4674, 1.0000, 0.4961]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8372, 0.3177, 0.8659, 0.3398]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3203, 0.0872, 0.3659, 0.1562],\n        [0.2578, 0.6068, 0.3008, 0.6198]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.0638, 0.2604, 0.0846, 0.2917]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7227, 0.6315, 0.8555, 0.6667]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9349, 0.8060, 0.9961, 1.0000],\n        [0.1471, 0.2422, 0.1667, 0.2500],\n        [0.8190, 0.3945, 0.9010, 0.4609],\n        [0.1237, 0.5651, 0.3281, 0.6680]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.6849, 0.3945, 0.7096, 0.4049]]), 'labels': tensor([1])}]\nbatch 14\nout :\n [{'boxes': tensor([[0.0000, 0.2103, 1.4559, 2.1212],\n        [0.0000, 0.1202, 0.4611, 1.9486]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1814, 0.0893], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.0885, 0.3372, 0.1094, 0.3594]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6406, 0.0599, 0.6628, 0.0690]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1393, 0.7943, 0.1654, 0.8268]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2474, 0.8932, 0.2812, 0.9193],\n        [0.0677, 0.2305, 0.0885, 0.2500],\n        [0.0299, 0.9779, 0.0560, 1.0000]]), 'labels': tensor([1, 1, 1])}]\nbatch 15\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1118, 0.5620, 1.5146],\n        [0.0000, 0.0815, 2.0502, 0.6135]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1134, 0.0603], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 9.3054e-02, 1.4561e+00, 2.3195e+00],\n        [2.2191e+02, 2.2280e+00, 2.2400e+02, 1.1562e+01],\n        [0.0000e+00, 9.0136e-02, 3.7776e-01, 2.8372e+00],\n        [2.2260e+02, 1.2653e+00, 2.2400e+02, 6.3084e+00],\n        [0.0000e+00, 1.1309e+00, 2.8628e+00, 1.0195e+01]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.6451, 0.3034, 0.2555, 0.2225, 0.0504], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.2461, 0.2565, 0.5286, 0.6146]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3945, 0.7917, 0.4792, 0.8190],\n        [0.7995, 0.7904, 0.8411, 0.8099]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.2930, 0.8099, 0.3008, 0.8203]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9479, 0.8424, 0.9805, 0.8828]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6315, 0.3711, 0.7305, 0.4258],\n        [0.4479, 0.3737, 0.7812, 0.5664]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.0404, 0.2565, 0.0482, 0.2630]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4102, 0.7344, 0.4518, 0.7708],\n        [0.1940, 0.8490, 0.2383, 0.8841]]), 'labels': tensor([1, 1])}]\nbatch 16\nout :\n [{'boxes': tensor([[0.0000, 0.1855, 1.2150, 1.7478]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1680], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1295, 1.5937, 1.9107]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.2856], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 2.5383e-02, 1.1179e+00, 1.7962e+00],\n        [0.0000e+00, 1.0315e-02, 4.3687e-01, 1.7200e+00],\n        [2.2042e+02, 1.9236e-01, 2.2358e+02, 1.8495e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.4858, 0.3746, 0.0800], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0558, 1.1670, 1.8495],\n        [0.0000, 0.0553, 0.4441, 2.2620]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.5007, 0.3937], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1692, 1.2886, 1.8956]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.5655], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.0781, 0.6758, 0.0951, 0.6901]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0781, 0.3958, 0.0977, 0.4102],\n        [0.1823, 0.3490, 0.2044, 0.3698],\n        [0.5482, 0.0260, 0.5677, 0.0508],\n        [0.4206, 0.2083, 0.4401, 0.2383],\n        [0.3633, 0.2852, 0.3932, 0.3177]]), 'labels': tensor([1, 1, 1, 1, 1])}, {'boxes': tensor([[0.1042, 0.6849, 0.2643, 0.7747]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9688, 0.7474, 0.9935, 0.7721]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3503, 0.7591, 0.3828, 0.7799]]), 'labels': tensor([1])}]\nbatch 17\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0959, 2.2164, 1.5455],\n        [0.0000, 0.0000, 0.9554, 1.0862],\n        [0.0000, 0.0000, 0.7898, 2.0424],\n        [0.0542, 0.2101, 3.6221, 1.8923]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.2603, 0.1036, 0.0711, 0.0631], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 1.1446e-01, 1.2463e+00, 1.7752e+00],\n        [2.2222e+02, 1.5508e+00, 2.2388e+02, 5.8439e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4237, 0.1508], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.2266, 0.1836, 0.2513, 0.2135]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1146, 0.5560, 0.1432, 0.5807],\n        [0.8815, 0.4310, 0.8958, 0.4440]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.9987, 0.0951, 1.0000, 0.1068]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8815, 0.3359, 0.9115, 0.3594]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0404, 0.7826, 0.0651, 0.7982]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4922, 0.0000, 0.7943, 0.2214]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8008, 0.8776, 0.8216, 0.8945],\n        [0.4427, 0.0078, 0.4570, 0.0273],\n        [0.3229, 0.0143, 0.5820, 0.2617]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.2878, 0.5885, 0.4505, 0.6576]]), 'labels': tensor([1])}]\nbatch 18\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[220.8195,   0.3552, 223.6205,   3.9640]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0516], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.2917, 1.8180],\n        [0.0000, 0.0090, 1.0503, 1.3858]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.2111, 0.1554], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0947, 0.9983, 2.1757]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1024], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5182, 0.6745, 0.5365, 0.6914],\n        [0.0898, 0.8151, 0.1198, 0.8451]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.6628, 0.7474, 0.6745, 0.7747]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3698, 0.4492, 0.3984, 0.4701]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4987, 0.1654, 0.6120, 0.3073]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9219, 0.3346, 0.9414, 0.3568]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0352, 0.1680, 0.1068, 0.2344]]), 'labels': tensor([1])}]\nbatch 19\nout :\n [{'boxes': tensor([[0.0000e+00, 3.2045e-02, 1.2365e+00, 1.8011e+00],\n        [0.0000e+00, 1.3498e-02, 5.5414e-01, 1.7810e+00],\n        [0.0000e+00, 1.2609e-01, 2.8632e+00, 2.0022e+00],\n        [0.0000e+00, 8.6791e-02, 2.1682e+00, 1.1231e+00],\n        [3.9131e-03, 1.9689e-02, 9.5366e-01, 9.3140e-01],\n        [2.6182e+00, 1.1068e-01, 8.6069e+00, 1.4956e+00],\n        [1.3567e+00, 1.5579e-01, 4.7619e+00, 1.3168e+00],\n        [0.0000e+00, 5.2842e-01, 3.1664e+00, 4.8170e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.6087, 0.4556, 0.3463, 0.2826, 0.2733, 0.1050, 0.0857, 0.0573],\n       device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2994, 1.7886, 3.3900]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0547], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 7.6213e-02, 1.2803e+00, 2.2691e+00],\n        [0.0000e+00, 1.0178e-01, 2.4853e+00, 1.7686e+00],\n        [0.0000e+00, 9.7088e-04, 8.9605e-01, 1.0518e+00],\n        [9.5553e-01, 1.1628e-01, 4.8294e+00, 1.5216e+00],\n        [2.7339e-03, 2.5630e-01, 9.9213e-01, 3.8305e+00],\n        [9.3288e-04, 3.6548e+00, 2.6811e-01, 9.2804e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.5180, 0.4363, 0.4350, 0.2543, 0.2018, 0.0750], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0125, 1.5423, 2.9329],\n        [0.0000, 0.0000, 0.8124, 2.2315]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.5448, 0.2725], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[ 0.0000,  0.1267,  1.5955,  2.5683],\n        [ 0.0000,  0.2754,  3.0095, 10.0605]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1817, 0.1195], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.3536, 1.3504, 2.7482]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1246], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1115, 1.2740, 1.9992],\n        [0.0000, 0.0670, 0.6892, 1.8602]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.3264, 0.2022], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5768, 0.0794, 0.6120, 0.1836],\n        [0.6042, 0.0729, 0.6263, 0.1536]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.3555, 0.5169, 0.4740, 0.6419]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0469, 0.7083, 0.1276, 0.8438]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3099, 0.4661, 0.4141, 0.5781]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7240, 0.1589, 0.7409, 0.1732]]), 'labels': tensor([1])}, {'boxes': tensor([[0.2109, 0.9518, 0.3138, 1.0000]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8307, 0.9896, 0.8398, 1.0000]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7539, 0.0872, 0.7904, 0.1042]]), 'labels': tensor([1])}]\nbatch 20\nout :\n [{'boxes': tensor([[0.0000, 0.0831, 1.1245, 1.7466],\n        [0.0000, 0.1773, 1.5167, 2.4673]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.2105, 0.0547], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[7.0111e-03, 2.9258e-02, 3.5823e-01, 1.9487e+00],\n        [2.1746e-02, 3.5639e-02, 1.1299e+00, 1.5513e+00],\n        [1.2856e-02, 1.3503e-01, 2.7550e+00, 2.2359e+00],\n        [2.2266e+02, 1.0016e+00, 2.2390e+02, 5.0199e+00],\n        [5.9671e-02, 5.1515e-01, 3.2300e+00, 4.9804e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.6942, 0.6420, 0.5430, 0.0965, 0.0634], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[2.2136e+02, 6.1940e-01, 2.2376e+02, 5.5314e+00],\n        [2.2017e+02, 8.1281e-01, 2.2339e+02, 7.9967e+00],\n        [0.0000e+00, 4.3408e-01, 1.7318e+00, 3.6986e+00],\n        [2.2118e+02, 2.2249e-01, 2.2386e+02, 2.2722e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.7308, 0.4310, 0.1722, 0.1198], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.6484, 0.9245, 0.7096, 0.9661],\n        [0.8333, 0.8854, 0.8919, 0.9271]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.6471, 0.3789, 0.6745, 0.4193],\n        [0.2474, 0.0677, 0.2799, 0.0885],\n        [0.2734, 0.0742, 0.3411, 0.1211],\n        [0.1901, 0.1289, 0.1966, 0.1458]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.4141, 0.5469, 0.6250, 0.5951]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4479, 0.2227, 0.4766, 0.2474]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4518, 0.4701, 0.4701, 0.4779],\n        [0.6341, 0.7891, 0.6628, 0.8138],\n        [0.7865, 0.7070, 0.8932, 0.7721]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.6680, 0.0859, 0.6927, 0.1055]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5781, 0.6133, 0.7396, 0.7682]]), 'labels': tensor([1])}]\nbatch 21\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1871, 1.5176, 2.4350],\n        [0.5046, 0.1884, 4.8545, 2.8921]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.2509, 0.0702], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[222.0310,   1.5222, 224.0000,   5.9032]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1054], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 2.4956e-01, 1.3278e+00, 2.9748e+00],\n        [1.6959e-02, 1.3437e-01, 8.0649e-01, 2.0738e+00],\n        [2.2162e+02, 2.5262e+00, 2.2363e+02, 7.6638e+00],\n        [2.2129e+02, 3.2100e-01, 2.2350e+02, 2.6295e+00],\n        [2.2255e+02, 1.3472e+00, 2.2381e+02, 5.5589e+00],\n        [0.0000e+00, 4.8483e-01, 2.5743e+00, 4.8801e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.5134, 0.3067, 0.1841, 0.0966, 0.0926, 0.0642], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5104, 0.5729, 0.7604, 0.7435]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6198, 0.1445, 0.7695, 0.2161]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3789, 0.4440, 0.5443, 0.5195]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1445, 0.5404, 0.4258, 0.6784]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7487, 0.7292, 0.9518, 0.7956],\n        [0.3984, 0.3307, 0.4727, 0.3633]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.4102, 0.7435, 0.4714, 0.7695],\n        [0.8802, 0.6510, 0.9375, 0.6667],\n        [0.0000, 0.7201, 0.0872, 0.7500],\n        [0.6523, 0.7135, 0.7331, 0.7409],\n        [0.8750, 0.6263, 0.9427, 0.6589],\n        [0.1419, 0.1914, 0.2513, 0.2292],\n        [0.0729, 0.9258, 0.1406, 0.9583]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1])}]\nbatch 22\nout :\n [{'boxes': tensor([[0.0000, 0.0667, 1.0919, 2.4330]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0679], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0037, 1.1108, 1.7883],\n        [0.0000, 0.0492, 0.8247, 3.1834]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.3254, 0.0773], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.3294, 0.4987, 0.3724, 0.6003]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0326, 0.1341, 0.0703, 0.1953]]), 'labels': tensor([1])}]\nbatch 23\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0000, 0.5507, 2.2958],\n        [0.0000, 0.0000, 1.0427, 1.7310]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4580, 0.4139], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 9.2307e-01, 4.6432e-01, 4.8482e+00],\n        [0.0000e+00, 8.1863e-02, 2.4755e-01, 2.3590e+00],\n        [2.1946e+02, 1.3696e-01, 2.2360e+02, 2.0956e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.0792, 0.0686, 0.0543], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 4.4750e+00, 1.0362e+00, 8.9874e+00],\n        [0.0000e+00, 4.2476e-01, 1.6542e+00, 3.6307e+00],\n        [2.2289e+02, 1.9222e+00, 2.2398e+02, 5.4750e+00],\n        [0.0000e+00, 1.7009e-01, 1.3614e+00, 1.8672e+00],\n        [2.2222e+02, 1.6871e+00, 2.2395e+02, 9.1237e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.3519, 0.3050, 0.2184, 0.1645, 0.1031], device='cuda:0',\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.9271, 0.0742, 0.9414, 0.0872],\n        [0.9206, 0.0482, 0.9323, 0.0599]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.8997, 0.0964, 0.9271, 0.1302]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4323, 0.0469, 0.4557, 0.0807],\n        [0.4206, 0.0534, 0.4479, 0.0872]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.7956, 0.8984, 0.8737, 0.9609],\n        [0.1003, 0.8711, 0.2188, 0.9661],\n        [0.7904, 0.9102, 0.8841, 0.9857],\n        [0.8099, 0.9453, 0.8594, 0.9883]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.1549, 0.4492, 0.3320, 0.7734]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6797, 0.1536, 0.7253, 0.2070],\n        [0.1862, 0.3750, 0.2344, 0.4062],\n        [0.6667, 0.1562, 0.6901, 0.1836],\n        [0.2070, 0.3555, 0.2487, 0.3815],\n        [0.2917, 0.0651, 0.3763, 0.1185],\n        [0.9076, 0.0534, 0.9583, 0.0911],\n        [0.1875, 0.3581, 0.2539, 0.4023]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1])}]\nbatch 24\nout :\n [{'boxes': tensor([[0.0000, 0.0418, 1.2616, 1.8161],\n        [0.0000, 0.0902, 2.1995, 1.2581],\n        [0.0000, 0.0126, 0.8505, 0.9513],\n        [1.0471, 0.1902, 5.1538, 1.7941],\n        [0.0000, 0.1300, 0.9678, 3.2867],\n        [0.0000, 0.5014, 2.9715, 4.6595]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.4546, 0.3658, 0.2798, 0.1254, 0.0647, 0.0632], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.8945, 0.6029, 0.9258, 0.6237]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3164, 0.0000, 0.4245, 0.1250]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1810, 0.1146, 0.1992, 0.1276]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5221, 0.0000, 0.5846, 0.0938],\n        [0.3294, 0.7461, 0.4570, 1.0000],\n        [0.4792, 0.0000, 0.6133, 0.2122]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.8685, 0.1471, 0.9036, 0.1875]]), 'labels': tensor([1])}]\nbatch 25\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0479, 1.0434, 2.0717],\n        [0.0000, 0.0383, 0.3321, 2.1525]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4141, 0.3065], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.9998, 0.8245, 4.8974]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1721], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.1210, 1.1689, 2.7004],\n        [0.0000, 0.0712, 1.3444, 1.3449],\n        [0.0000, 0.0621, 0.7486, 2.0345],\n        [0.0000, 0.4858, 2.7860, 4.8652]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.6952, 0.6646, 0.5622, 0.0508], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0503, 1.2921, 2.5854]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.6045], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.4792, 0.5234, 0.5104, 0.5495]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4635, 0.4466, 0.4766, 0.4609]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6224, 0.1341, 0.6419, 0.1523],\n        [0.3919, 0.4648, 0.4323, 0.5534],\n        [0.3958, 0.5521, 0.4089, 0.5716]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.5872, 0.8385, 0.6068, 0.8607]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6901, 0.4245, 0.6979, 0.4388],\n        [0.6432, 0.5312, 0.6953, 0.6328]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.1146, 0.2930, 0.2109, 0.4049]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7786, 0.4453, 0.8372, 0.4701]]), 'labels': tensor([1])}]\nbatch 26\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[221.1448,   1.2031, 223.5607,   9.9102],\n        [  0.0000,   0.2634,   1.3304,   2.5905]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.1327, 0.0991], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.2708, 0.7500, 0.4753, 0.7891]]), 'labels': tensor([1])}, {'boxes': tensor([[0.7253, 0.1419, 0.7747, 0.2513]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6237, 0.7591, 0.6341, 0.7656]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5781, 0.9089, 0.6875, 0.9466]]), 'labels': tensor([1])}, {'boxes': tensor([[0.8307, 0.0612, 0.8646, 0.0807]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9987, 0.0312, 1.0000, 0.0443]]), 'labels': tensor([1])}]\nbatch 27\nout :\n [{'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000e+00, 5.1439e-02, 1.2213e+00, 2.0324e+00],\n        [2.2257e+02, 1.6462e+00, 2.2396e+02, 6.2402e+00]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1], device='cuda:0'), 'scores': tensor([0.4320, 0.1787], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0313, 1.1727, 1.6551],\n        [0.0000, 0.0200, 0.3816, 1.8708],\n        [0.0000, 0.0910, 2.1405, 1.0031],\n        [0.0000, 0.0749, 0.9274, 3.1997]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.3466, 0.2233, 0.1581, 0.1253], device='cuda:0',\n       grad_fn=<IndexBackward0>)}, {'boxes': tensor([[221.9132,   1.7935, 223.8778,   6.9636]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.5792], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2877, 1.6088, 2.1568]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1311], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0609, 1.4525, 2.0879]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1410], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5703, 0.8516, 0.6576, 0.8815],\n        [0.0898, 0.1628, 0.1927, 0.3229],\n        [0.9245, 0.3438, 0.9518, 0.3711]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.0156, 0.4661, 0.2969, 0.5534]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3737, 0.9154, 0.3906, 0.9310]]), 'labels': tensor([1])}, {'boxes': tensor([[0.9987, 0.8320, 1.0000, 0.8477]]), 'labels': tensor([1])}, {'boxes': tensor([[0.0547, 0.6328, 0.1576, 0.6615]]), 'labels': tensor([1])}, {'boxes': tensor([[0.6263, 0.5495, 0.6992, 0.6081],\n        [0.6133, 0.5664, 0.6953, 0.6302]]), 'labels': tensor([1, 1])}, {'boxes': tensor([[0.2070, 0.4609, 0.2773, 0.4909],\n        [0.6745, 0.1719, 0.8021, 0.2318]]), 'labels': tensor([1, 1])}]\nbatch 28\nout :\n [{'boxes': tensor([[2.1961e+02, 8.7718e-02, 2.2360e+02, 1.9728e+00],\n        [2.2290e+02, 1.7773e+00, 2.2396e+02, 5.9502e+00],\n        [0.0000e+00, 3.0116e-02, 6.6336e-01, 6.8761e-01]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1], device='cuda:0'), 'scores': tensor([0.0797, 0.0710, 0.0536], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([], device='cuda:0', size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.2823, 1.7329, 3.0830]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.2384], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.3507, 1.7643, 3.2704]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.1006], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[0.0000, 0.0262, 1.3077, 2.3847]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.0743], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[222.2483,   1.2807, 223.8351,   9.8254],\n        [  0.0000,   0.2285,   1.3625,   2.8322],\n        [  0.0000,   5.2194,   1.0929,  10.7426],\n        [221.1227,   1.2624, 223.8208,   5.4774]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.4006, 0.1792, 0.1005, 0.0892], device='cuda:0',\n       grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.5078, 0.2799, 0.5404, 0.3073],\n        [0.2409, 0.7734, 0.4284, 0.9362],\n        [0.3477, 0.1823, 0.4440, 0.2513]]), 'labels': tensor([1, 1, 1])}, {'boxes': tensor([[0.5885, 0.6680, 0.7083, 0.7292]]), 'labels': tensor([1])}, {'boxes': tensor([[0.4518, 0.8034, 0.4701, 0.8112]]), 'labels': tensor([1])}, {'boxes': tensor([[0.5807, 0.4714, 0.9102, 0.5924]]), 'labels': tensor([1])}, {'boxes': tensor([[0.1172, 0.6159, 0.3542, 0.7786]]), 'labels': tensor([1])}, {'boxes': tensor([[0.3060, 0.0612, 0.3073, 0.0625],\n        [0.3138, 0.0690, 0.4258, 0.1159],\n        [0.3060, 0.0495, 0.3294, 0.0599],\n        [0.3320, 0.0404, 0.3490, 0.0521]]), 'labels': tensor([1, 1, 1, 1])}, {'boxes': tensor([[0.0260, 0.9570, 0.1068, 0.9987],\n        [0.5898, 0.4102, 0.6484, 0.4596],\n        [0.5599, 0.3594, 0.6732, 0.4570]]), 'labels': tensor([1, 1, 1])}]\nbatch 29\nout :\n [{'boxes': tensor([[0.0000, 0.0959, 1.4329, 2.3523]], device='cuda:0',\n       grad_fn=<StackBackward0>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.5190], device='cuda:0', grad_fn=<IndexBackward0>)}]\ntarget :\n [{'boxes': tensor([[0.3672, 0.8086, 0.4062, 0.8320]]), 'labels': tensor([1])}]\nMean Average Precision: 0.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"# TRAIN AGAIN (Continue training)\n\nimport pickle\n\nif train_again:    \n    # Load loaders\n    train_loader = torch.load(os.path.join(model_filepath, 'train_loader.pt'))\n    val_loader = torch.load(os.path.join(model_filepath, 'val_loader.pt'))\n    test_loader = torch.load(os.path.join(model_filepath, 'test_loader.pt'))\n    print(\"Loadeders and model loaded succesfully\") \n    \n    print(f\"{device = }\")\n    \n    # Load model from checkpoint\n    checkpoint = torch.load(os.path.join(model_filepath, \"model.tar\"))\n    \n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn() # this should create an untrained model\n    \n    for name, param in model.named_parameters():\n          param.requires_grad = False\n    num_classes = 2 # background, ship\n    \n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    \n    model.load_state_dict(checkpoint['model_state_dict'])\n    model = model.to(device)\n    \n    optimizer = optim.Adam(params = model.parameters(), weight_decay=0.01, lr = 1e-2)\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    \n    scheduler = torch.optim.lr_scheduler.LambdaLR(\n        optimizer,\n        lr_lambda = lambda epoch: 0.8 ** epoch,\n    )\n    \n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    \n    training_loss = checkpoint['training_loss']\n    # epoch = checkpoint['epoch'] # non serve -> rimuovi\n    \n    torch.compile(model)\n    a\n    train(model, optimizer, scheduler, torch.nn.CrossEntropyLoss(), train_loader, val_loader, training_loss, epochs=num_epochs, device=device)\n    \n    fig, ax = plt.subplots()\n    ax.plot(lrs)    \n    ax.set(xlabel='epoch', ylabel='learning rate value')\n    fig.savefig(os.path.join(model_filepath, \"lrs.png\")) # decimal scale -> the output is hard to read, instead try with this: \n    print(f\"{lrs = }\")\n    logger.info(f\"{lrs = }\")\n\n    # Resume training from a specific epoch\n    # optimizer = optim.Adam(params = model.parameters(), lr=0.01)\n    \n    # Il file salvato model.tar contiene optiimzer, scheduler, loss e tanto altro\n\n    # train(model, model.optimizer, model.scheduler, torch.nn.CrossEntropyLoss(), train_loader, val_loader, epochs=num_epochs, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:46:44.529196Z","iopub.status.idle":"2024-06-02T14:46:44.529709Z","shell.execute_reply.started":"2024-06-02T14:46:44.529427Z","shell.execute_reply":"2024-06-02T14:46:44.529447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# correct = 0\n# total = 0\n# with torch.no_grad():\n#     for data in val_loader:\n#         images, labels = data[0].to(device), data[1].to(device)\n#         predictions = torch.argmax(model(images),dim=1)\n\n#         total += labels.size(0)\n#         correct += (predictions == labels).sum().item()\n\n# print('accuracy = {:f}'.format(correct / total))\n# print('correct: {:d}  total: {:d}'.format(correct, total))","metadata":{"_uuid":"ce6b85c5-91c9-488b-9ae0-74bd3514487f","_cell_guid":"93e16d46-9dc5-41c7-8837-52d4920e6149","id":"MLPxPQrile1o","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-21T07:41:13.044527Z","iopub.execute_input":"2024-05-21T07:41:13.045158Z","iopub.status.idle":"2024-05-21T07:41:13.054176Z","shell.execute_reply.started":"2024-05-21T07:41:13.045063Z","shell.execute_reply":"2024-05-21T07:41:13.052798Z"}}},{"cell_type":"code","source":"\n\n\n\nenf e' intelligente, simo e' bello, ludo e' intelligente, enf ludo e' bella, e' attraente, \n\n\nsimo e' attraenteludo e' intelligenteenf e' bellosimo e'ludo e' buona\nattraente\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimo e' bello, \n\n\nsimo e' intelligenteenf e' attraente\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T14:46:44.531299Z","iopub.status.idle":"2024-06-02T14:46:44.531666Z","shell.execute_reply.started":"2024-06-02T14:46:44.531497Z","shell.execute_reply":"2024-06-02T14:46:44.531511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}